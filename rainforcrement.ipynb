{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQjO9Ia1RduZ9n30wMoRTJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminatulmaimuna/machine-learning-sesi-10/blob/main/rainforcrement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oxO2x_btUcqx"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "id": "b_3A4BFZVWUM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncBghsF0Vflt",
        "outputId": "ce84d8b5-5295-4353-f78f-e22c6d98dc53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_map = [\n",
        "    \"SFFFH\",\n",
        "    \"HFHFF\",\n",
        "    \"FFFHF\",\n",
        "    \"FHFFF\",\n",
        "    \"HFFFG\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELGMORxdVirI",
        "outputId": "40580250-741e-4be5-d52b-1b22c3a8e0ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import resource_stream, resource_exists\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.11/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP80vcjSVoHZ",
        "outputId": "fa4e222c-6aec-4c96-a632-dbc0d67f1a69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 25\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training parameters\n",
        "num_episodes = 10000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ],
      "metadata": {
        "id": "rAV6ZGw6VteU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP0MI_DOVx7d",
        "outputId": "404d8573-09cb-465a-d494-9cee8a2260eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9888 episode and 2 step\n",
            "Delta Q = 0.9243073775290531\n",
            "Q_table[0,3]_old = 0.2418236980147779\n",
            "Q_table[(0, 3)]_new = 0.24194870574235325\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9888 episode and 3 step\n",
            "Delta Q = 0.9243073775290531\n",
            "Q_table[0,3]_old = 0.24194870574235325\n",
            "Q_table[(0, 3)]_new = 0.24206121269717104\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9888 episode and 4 step\n",
            "Delta Q = 0.9243073775290531\n",
            "Q_table[0,3]_old = 0.24206121269717104\n",
            "Q_table[(0, 3)]_new = 0.24216246895650706\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9888 episode and 5 step\n",
            "Delta Q = 0.9243073775290531\n",
            "Q_table[0,3]_old = 0.24216246895650706\n",
            "Q_table[(0, 3)]_new = 0.2422535995899095\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9888 episode and 6 step\n",
            "Delta Q = 0.9243073775290531\n",
            "Q_table[0,3]_old = 0.2422535995899095\n",
            "Q_table[(0, 3)]_new = 0.24233561715997168\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9888 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9889 episode and 0 step\n",
            "Delta Q = 0.9246944171862929\n",
            "Q_table[0,2]_old = 0.24552906595003154\n",
            "Q_table[(0, 2)]_new = 0.24567057654132124\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9889 episode and 1 step\n",
            "Delta Q = 0.9251684645443168\n",
            "Q_table[1,2]_old = 0.24943855743730153\n",
            "Q_table[(1, 2)]_new = 0.24966316623788815\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9889 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9890 episode and 0 step\n",
            "Delta Q = 0.9247166534575509\n",
            "Q_table[0,2]_old = 0.24567057654132124\n",
            "Q_table[(0, 2)]_new = 0.24582017234474005\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9890 episode and 1 step\n",
            "Delta Q = 0.9234477536066478\n",
            "Q_table[1,1]_old = 0.2330112185992102\n",
            "Q_table[(1, 1)]_new = 0.23315785034593695\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9890 episode and 2 step\n",
            "Delta Q = 0.9247166534575509\n",
            "Q_table[6,3]_old = 0.2368459960267448\n",
            "Q_table[(6, 3)]_new = 0.23787804988162126\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9890 episode and 3 step\n",
            "Delta Q = 0.9243361970621293\n",
            "Q_table[1,0]_old = 0.24008656665162284\n",
            "Q_table[(1, 0)]_new = 0.24041410704858984\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9890 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9891 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9892 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9893 episode and 0 step\n",
            "Delta Q = 0.9247166534575509\n",
            "Q_table[0,2]_old = 0.24582017234474005\n",
            "Q_table[(0, 2)]_new = 0.24595480856781696\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9893 episode and 1 step\n",
            "Delta Q = 0.9251684645443168\n",
            "Q_table[1,2]_old = 0.24966316623788815\n",
            "Q_table[(1, 2)]_new = 0.24986531415841612\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9893 episode and 2 step\n",
            "Delta Q = 0.9259727341861362\n",
            "Q_table[2,2]_old = 0.2542269145890583\n",
            "Q_table[(2, 2)]_new = 0.2547769573162887\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9893 episode and 3 step\n",
            "Delta Q = 0.927970232808875\n",
            "Q_table[3,1]_old = 0.2623508503650126\n",
            "Q_table[(3, 1)]_new = 0.2640859981373863\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9893 episode and 4 step\n",
            "Delta Q = 0.9261445138156013\n",
            "Q_table[8,3]_old = 0.21675593971575075\n",
            "Q_table[(8, 3)]_new = 0.22122485955977694\n",
            "We are on 8 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9893 episode and 5 step\n",
            "Delta Q = 0.927970232808875\n",
            "Q_table[3,1]_old = 0.2640859981373863\n",
            "Q_table[(3, 1)]_new = 0.26564763113252265\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9893 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9894 episode and 0 step\n",
            "Delta Q = 0.9243495260482139\n",
            "Q_table[0,3]_old = 0.24233561715997168\n",
            "Q_table[(0, 3)]_new = 0.2424515814921884\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9894 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9895 episode and 0 step\n",
            "Delta Q = 0.9247366661016833\n",
            "Q_table[0,2]_old = 0.24595480856781696\n",
            "Q_table[(0, 2)]_new = 0.24609599381271846\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9895 episode and 1 step\n",
            "Delta Q = 0.9243635033874591\n",
            "Q_table[1,0]_old = 0.24041410704858984\n",
            "Q_table[(1, 0)]_new = 0.24073619973118998\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9895 episode and 2 step\n",
            "Delta Q = 0.9247366661016833\n",
            "Q_table[0,2]_old = 0.24609599381271846\n",
            "Q_table[(0, 2)]_new = 0.24622306053312984\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9895 episode and 3 step\n",
            "Delta Q = 0.9235499269382805\n",
            "Q_table[1,1]_old = 0.23315785034593695\n",
            "Q_table[(1, 1)]_new = 0.23339199224962376\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9895 episode and 4 step\n",
            "Delta Q = 0.9216533066672993\n",
            "Q_table[6,1]_old = 0.2125574548523896\n",
            "Q_table[(6, 1)]_new = 0.21295501603444994\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9895 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,1]_old = 0.0\n",
            "Q_table[(11, 1)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9896 episode and 0 step\n",
            "Delta Q = 0.9243760829927798\n",
            "Q_table[0,3]_old = 0.2424515814921884\n",
            "Q_table[(0, 3)]_new = 0.2425825063357494\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9896 episode and 1 step\n",
            "Delta Q = 0.9243760829927798\n",
            "Q_table[0,3]_old = 0.2425825063357494\n",
            "Q_table[(0, 3)]_new = 0.24270033869495433\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9896 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9897 episode and 0 step\n",
            "Delta Q = 0.9243760829927798\n",
            "Q_table[0,3]_old = 0.24270033869495433\n",
            "Q_table[(0, 3)]_new = 0.24280638781823877\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9897 episode and 1 step\n",
            "Delta Q = 0.9247366661016833\n",
            "Q_table[0,2]_old = 0.24622306053312984\n",
            "Q_table[(0, 2)]_new = 0.24633742058150007\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9897 episode and 2 step\n",
            "Delta Q = 0.9235499269382805\n",
            "Q_table[1,1]_old = 0.23339199224962376\n",
            "Q_table[(1, 1)]_new = 0.2336027199629419\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9897 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9898 episode and 0 step\n",
            "Delta Q = 0.9243874046375685\n",
            "Q_table[0,0]_old = 0.2415939387854396\n",
            "Q_table[(0, 0)]_new = 0.24182194954446415\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9898 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9899 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9900 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 0 step\n",
            "Delta Q = 0.9243874046375685\n",
            "Q_table[0,0]_old = 0.24182194954446415\n",
            "Q_table[(0, 0)]_new = 0.24202715922758625\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 1 step\n",
            "Delta Q = 0.9243874046375685\n",
            "Q_table[0,3]_old = 0.24280638781823877\n",
            "Q_table[(0, 3)]_new = 0.2429131536739834\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 2 step\n",
            "Delta Q = 0.9247366661016833\n",
            "Q_table[0,2]_old = 0.24633742058150007\n",
            "Q_table[(0, 2)]_new = 0.24644034462503328\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 3 step\n",
            "Delta Q = 0.9243975941178784\n",
            "Q_table[1,0]_old = 0.24073619973118998\n",
            "Q_table[(1, 0)]_new = 0.24106017387594927\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 4 step\n",
            "Delta Q = 0.9243975941178784\n",
            "Q_table[0,0]_old = 0.24202715922758625\n",
            "Q_table[(0, 0)]_new = 0.2422220374227059\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 5 step\n",
            "Delta Q = 0.9247366661016833\n",
            "Q_table[0,2]_old = 0.24644034462503328\n",
            "Q_table[(0, 2)]_new = 0.24653297626421317\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 6 step\n",
            "Delta Q = 0.9247366661016833\n",
            "Q_table[1,3]_old = 0.24284734223478466\n",
            "Q_table[(1, 3)]_new = 0.2432992741129894\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 7 step\n",
            "Delta Q = 0.9252229187743126\n",
            "Q_table[1,2]_old = 0.24986531415841612\n",
            "Q_table[(1, 2)]_new = 0.2501017015168871\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 8 step\n",
            "Delta Q = 0.9262991154821197\n",
            "Q_table[2,2]_old = 0.2547769573162887\n",
            "Q_table[(2, 2)]_new = 0.25559837706677957\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 9 step\n",
            "Delta Q = 0.927970232808875\n",
            "Q_table[3,1]_old = 0.26564763113252265\n",
            "Q_table[(3, 1)]_new = 0.2670531008281454\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 10 step\n",
            "Delta Q = 0.9316793336938153\n",
            "Q_table[8,2]_old = 0.2825276041300504\n",
            "Q_table[(8, 2)]_new = 0.2859541774108607\n",
            "We are on 8 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 11 step\n",
            "Delta Q = 0.9316793336938153\n",
            "Q_table[9,2]_old = 0.25472692313952583\n",
            "Q_table[(9, 2)]_new = 0.26093356451938854\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 12 step\n",
            "Delta Q = 0.9316793336938153\n",
            "Q_table[9,2]_old = 0.26093356451938854\n",
            "Q_table[(9, 2)]_new = 0.26651954176126497\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 13 step\n",
            "Delta Q = 0.9316793336938153\n",
            "Q_table[9,2]_old = 0.26651954176126497\n",
            "Q_table[(9, 2)]_new = 0.2715469212789538\n",
            "We are on 9 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9901 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[9,3]_old = 0.0\n",
            "Q_table[(9, 3)]_new = 0.0\n",
            "We are on 9 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 0 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,3]_old = 0.2429131536739834\n",
            "Q_table[(0, 3)]_new = 0.24302860295674217\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 1 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,3]_old = 0.24302860295674217\n",
            "Q_table[(0, 3)]_new = 0.24313250731122504\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 2 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,0]_old = 0.2422220374227059\n",
            "Q_table[(0, 0)]_new = 0.24240659833059242\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 3 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,3]_old = 0.24313250731122504\n",
            "Q_table[(0, 3)]_new = 0.24322602123025966\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 4 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,3]_old = 0.24322602123025966\n",
            "Q_table[(0, 3)]_new = 0.24331018375739083\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 5 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,3]_old = 0.24331018375739083\n",
            "Q_table[(0, 3)]_new = 0.24338593003180886\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 6 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,3]_old = 0.24338593003180886\n",
            "Q_table[(0, 3)]_new = 0.24345410167878506\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 7 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,0]_old = 0.24240659833059242\n",
            "Q_table[(0, 0)]_new = 0.2425727031476903\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 8 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,3]_old = 0.24345410167878506\n",
            "Q_table[(0, 3)]_new = 0.24351545616106368\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 9 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,0]_old = 0.2425727031476903\n",
            "Q_table[(0, 0)]_new = 0.24272219748307838\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9902 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9903 episode and 0 step\n",
            "Delta Q = 0.9244067646501571\n",
            "Q_table[0,0]_old = 0.24272219748307838\n",
            "Q_table[(0, 0)]_new = 0.24285674238492766\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9903 episode and 1 step\n",
            "Delta Q = 0.9247600684501719\n",
            "Q_table[0,2]_old = 0.24653297626421317\n",
            "Q_table[(0, 2)]_new = 0.24663974708796366\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9903 episode and 2 step\n",
            "Delta Q = 0.9247600684501719\n",
            "Q_table[1,3]_old = 0.2432992741129894\n",
            "Q_table[(1, 3)]_new = 0.2437294151518623\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9903 episode and 3 step\n",
            "Delta Q = 0.9235499269382805\n",
            "Q_table[1,1]_old = 0.2336027199629419\n",
            "Q_table[(1, 1)]_new = 0.23379237490492824\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9903 episode and 4 step\n",
            "Delta Q = 0.9216533066672993\n",
            "Q_table[6,1]_old = 0.21295501603444994\n",
            "Q_table[(6, 1)]_new = 0.21331282109830424\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9903 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,1]_old = 0.0\n",
            "Q_table[(11, 1)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 0 step\n",
            "Delta Q = 0.9244173349617084\n",
            "Q_table[0,0]_old = 0.24285674238492766\n",
            "Q_table[(0, 0)]_new = 0.2429884031081433\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 1 step\n",
            "Delta Q = 0.9244173349617084\n",
            "Q_table[0,0]_old = 0.2429884031081433\n",
            "Q_table[(0, 0)]_new = 0.24310689775903735\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 2 step\n",
            "Delta Q = 0.9247600684501719\n",
            "Q_table[0,2]_old = 0.24663974708796366\n",
            "Q_table[(0, 2)]_new = 0.24673584082933914\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 3 step\n",
            "Delta Q = 0.9235499269382805\n",
            "Q_table[1,1]_old = 0.23379237490492824\n",
            "Q_table[(1, 1)]_new = 0.23396306435271594\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 4 step\n",
            "Delta Q = 0.9247600684501719\n",
            "Q_table[6,3]_old = 0.23787804988162126\n",
            "Q_table[(6, 3)]_new = 0.23885031334363094\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 5 step\n",
            "Delta Q = 0.9253042393296111\n",
            "Q_table[1,2]_old = 0.2501017015168871\n",
            "Q_table[(1, 2)]_new = 0.25039577069480956\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 6 step\n",
            "Delta Q = 0.9253042393296111\n",
            "Q_table[2,3]_old = 0.24719798302904122\n",
            "Q_table[(2, 3)]_new = 0.2477824240557483\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 7 step\n",
            "Delta Q = 0.9264382569819865\n",
            "Q_table[2,2]_old = 0.25559837706677957\n",
            "Q_table[(2, 2)]_new = 0.25647679634208803\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9904 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9905 episode and 0 step\n",
            "Delta Q = 0.9247891812987862\n",
            "Q_table[0,2]_old = 0.24673584082933914\n",
            "Q_table[(0, 2)]_new = 0.24685143804519138\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9905 episode and 1 step\n",
            "Delta Q = 0.9236461810210195\n",
            "Q_table[1,1]_old = 0.23396306435271594\n",
            "Q_table[(1, 1)]_new = 0.2342129389384638\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9905 episode and 2 step\n",
            "Delta Q = 0.9247891812987862\n",
            "Q_table[6,3]_old = 0.23885031334363094\n",
            "Q_table[(6, 3)]_new = 0.239754463308054\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9905 episode and 3 step\n",
            "Delta Q = 0.9237356918674974\n",
            "Q_table[1,1]_old = 0.2342129389384638\n",
            "Q_table[(1, 1)]_new = 0.23452733691211478\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9905 episode and 4 step\n",
            "Delta Q = 0.9247891812987862\n",
            "Q_table[6,3]_old = 0.239754463308054\n",
            "Q_table[(6, 3)]_new = 0.24056819827603476\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9905 episode and 5 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.23452733691211478\n",
            "Q_table[(1, 1)]_new = 0.23489085485023073\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9905 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9906 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9907 episode and 0 step\n",
            "Delta Q = 0.924438292366474\n",
            "Q_table[0,0]_old = 0.24310689775903735\n",
            "Q_table[(0, 0)]_new = 0.24323450034960759\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9907 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9908 episode and 0 step\n",
            "Delta Q = 0.924438292366474\n",
            "Q_table[0,0]_old = 0.24323450034960759\n",
            "Q_table[(0, 0)]_new = 0.2433493426811208\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9908 episode and 1 step\n",
            "Delta Q = 0.9247891812987862\n",
            "Q_table[0,2]_old = 0.24685143804519138\n",
            "Q_table[(0, 2)]_new = 0.2469554755394584\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9908 episode and 2 step\n",
            "Delta Q = 0.9247891812987862\n",
            "Q_table[1,3]_old = 0.2437294151518623\n",
            "Q_table[(1, 3)]_new = 0.24414565493546223\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9908 episode and 3 step\n",
            "Delta Q = 0.9253912028378667\n",
            "Q_table[1,2]_old = 0.25039577069480956\n",
            "Q_table[(1, 2)]_new = 0.2507473964631953\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9908 episode and 4 step\n",
            "Delta Q = 0.9264382569819865\n",
            "Q_table[2,2]_old = 0.25647679634208803\n",
            "Q_table[(2, 2)]_new = 0.25726737368986563\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9908 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 0 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[0,2]_old = 0.2469554755394584\n",
            "Q_table[(0, 2)]_new = 0.2470839202353689\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 1 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[1,3]_old = 0.24414565493546223\n",
            "Q_table[(1, 3)]_new = 0.24455508169177234\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 2 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[1,3]_old = 0.24455508169177234\n",
            "Q_table[(1, 3)]_new = 0.24492356577245145\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 3 step\n",
            "Delta Q = 0.9244613081033015\n",
            "Q_table[1,0]_old = 0.24106017387594927\n",
            "Q_table[(1, 0)]_new = 0.24141546459165586\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 4 step\n",
            "Delta Q = 0.9244613081033015\n",
            "Q_table[0,0]_old = 0.2433493426811208\n",
            "Q_table[(0, 0)]_new = 0.24347571651631025\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 5 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[0,2]_old = 0.2470839202353689\n",
            "Q_table[(0, 2)]_new = 0.24719952046168836\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 6 step\n",
            "Delta Q = 0.9244727525257072\n",
            "Q_table[1,0]_old = 0.24141546459165586\n",
            "Q_table[(1, 0)]_new = 0.24174667065819744\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 7 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[0,2]_old = 0.24719952046168836\n",
            "Q_table[(0, 2)]_new = 0.24730356066537587\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 8 step\n",
            "Delta Q = 0.9244830525058723\n",
            "Q_table[1,0]_old = 0.24174667065819744\n",
            "Q_table[(1, 0)]_new = 0.2420550560982499\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 9 step\n",
            "Delta Q = 0.9244830525058723\n",
            "Q_table[0,3]_old = 0.24351545616106368\n",
            "Q_table[(0, 3)]_new = 0.24364696305082953\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9909 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 0 step\n",
            "Delta Q = 0.9244830525058723\n",
            "Q_table[0,3]_old = 0.24364696305082953\n",
            "Q_table[(0, 3)]_new = 0.2437653192516188\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 1 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[0,2]_old = 0.24730356066537587\n",
            "Q_table[(0, 2)]_new = 0.24739719684869463\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 2 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[1,3]_old = 0.24492356577245145\n",
            "Q_table[(1, 3)]_new = 0.24525520144506266\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 3 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.23489085485023073\n",
            "Q_table[(1, 1)]_new = 0.2352180209945351\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 4 step\n",
            "Delta Q = 0.9216533066672993\n",
            "Q_table[6,1]_old = 0.21331282109830424\n",
            "Q_table[(6, 1)]_new = 0.2136348456557731\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 5 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[11,3]_old = 0.2187202693666595\n",
            "Q_table[(11, 3)]_new = 0.22066449405932098\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 6 step\n",
            "Delta Q = 0.9218457849118729\n",
            "Q_table[6,1]_old = 0.2136348456557731\n",
            "Q_table[(6, 1)]_new = 0.21411714600206858\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 7 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[11,3]_old = 0.22066449405932098\n",
            "Q_table[(11, 3)]_new = 0.22241429628271633\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 8 step\n",
            "Delta Q = 0.9220190153319889\n",
            "Q_table[6,1]_old = 0.21411714600206858\n",
            "Q_table[(6, 1)]_new = 0.21472444673385063\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 9 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[11,3]_old = 0.22241429628271633\n",
            "Q_table[(11, 3)]_new = 0.22398911828377213\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 10 step\n",
            "Delta Q = 0.9221749227100935\n",
            "Q_table[6,1]_old = 0.21472444673385063\n",
            "Q_table[(6, 1)]_new = 0.21542692477055903\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 11 step\n",
            "Delta Q = 0.9167133885304355\n",
            "Q_table[11,2]_old = 0.1469461571048642\n",
            "Q_table[(11, 2)]_new = 0.14896492992481322\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9910 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,2]_old = 0.0\n",
            "Q_table[(12, 2)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9911 episode and 0 step\n",
            "Delta Q = 0.9244923224880208\n",
            "Q_table[0,0]_old = 0.24347571651631025\n",
            "Q_table[(0, 0)]_new = 0.24362046735270002\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9911 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9912 episode and 0 step\n",
            "Delta Q = 0.9244923224880208\n",
            "Q_table[0,3]_old = 0.2437653192516188\n",
            "Q_table[(0, 3)]_new = 0.2438811098144777\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9912 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9913 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9914 episode and 0 step\n",
            "Delta Q = 0.9244923224880208\n",
            "Q_table[0,3]_old = 0.2438811098144777\n",
            "Q_table[(0, 3)]_new = 0.2439853213210507\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9914 episode and 1 step\n",
            "Delta Q = 0.9244923224880208\n",
            "Q_table[0,3]_old = 0.2439853213210507\n",
            "Q_table[(0, 3)]_new = 0.2440791116769664\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9914 episode and 2 step\n",
            "Delta Q = 0.9244923224880208\n",
            "Q_table[0,3]_old = 0.2440791116769664\n",
            "Q_table[(0, 3)]_new = 0.24416352299729052\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9914 episode and 3 step\n",
            "Delta Q = 0.9244923224880208\n",
            "Q_table[0,3]_old = 0.24416352299729052\n",
            "Q_table[(0, 3)]_new = 0.24423949318558225\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9914 episode and 4 step\n",
            "Delta Q = 0.9244923224880208\n",
            "Q_table[0,3]_old = 0.24423949318558225\n",
            "Q_table[(0, 3)]_new = 0.2443078663550448\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9914 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9915 episode and 0 step\n",
            "Delta Q = 0.9248239922498563\n",
            "Q_table[0,2]_old = 0.24739719684869463\n",
            "Q_table[(0, 2)]_new = 0.24748146941368152\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9915 episode and 1 step\n",
            "Delta Q = 0.9254694699952967\n",
            "Q_table[1,2]_old = 0.2507473964631953\n",
            "Q_table[(1, 2)]_new = 0.25114212681217246\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9915 episode and 2 step\n",
            "Delta Q = 0.9264382569819865\n",
            "Q_table[2,2]_old = 0.25726737368986563\n",
            "Q_table[(2, 2)]_new = 0.25797889330286544\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9915 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 0 step\n",
            "Delta Q = 0.9248630705544051\n",
            "Q_table[0,2]_old = 0.24748146941368152\n",
            "Q_table[(0, 2)]_new = 0.24759639302671843\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 1 step\n",
            "Delta Q = 0.9255399104369837\n",
            "Q_table[1,2]_old = 0.25114212681217246\n",
            "Q_table[(1, 2)]_new = 0.2515678245679389\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 2 step\n",
            "Delta Q = 0.9264382569819865\n",
            "Q_table[2,2]_old = 0.25797889330286544\n",
            "Q_table[(2, 2)]_new = 0.2586192609545653\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 3 step\n",
            "Delta Q = 0.925603306834502\n",
            "Q_table[3,0]_old = 0.2360280193669376\n",
            "Q_table[(3, 0)]_new = 0.2380285242647458\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 4 step\n",
            "Delta Q = 0.924905214632226\n",
            "Q_table[2,0]_old = 0.23827730465894095\n",
            "Q_table[(2, 0)]_new = 0.2393547888252728\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 5 step\n",
            "Delta Q = 0.925603306834502\n",
            "Q_table[1,2]_old = 0.2515678245679389\n",
            "Q_table[(1, 2)]_new = 0.252014348945647\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 6 step\n",
            "Delta Q = 0.9249494205456191\n",
            "Q_table[2,0]_old = 0.2393547888252728\n",
            "Q_table[(2, 0)]_new = 0.24036873048836457\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 7 step\n",
            "Delta Q = 0.9245120429096452\n",
            "Q_table[1,0]_old = 0.2420550560982499\n",
            "Q_table[(1, 0)]_new = 0.24236159339807004\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 8 step\n",
            "Delta Q = 0.9249494205456191\n",
            "Q_table[0,2]_old = 0.24759639302671843\n",
            "Q_table[(0, 2)]_new = 0.24778617426966565\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 9 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.2352180209945351\n",
            "Q_table[(1, 1)]_new = 0.23551247052440902\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 10 step\n",
            "Delta Q = 0.9221749227100935\n",
            "Q_table[6,1]_old = 0.21542692477055903\n",
            "Q_table[(6, 1)]_new = 0.21605915500359657\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9916 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,1]_old = 0.0\n",
            "Q_table[(11, 1)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9917 episode and 0 step\n",
            "Delta Q = 0.924530831252697\n",
            "Q_table[0,3]_old = 0.2443078663550448\n",
            "Q_table[(0, 3)]_new = 0.24440791097223724\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9917 episode and 1 step\n",
            "Delta Q = 0.924530831252697\n",
            "Q_table[0,0]_old = 0.24362046735270002\n",
            "Q_table[(0, 0)]_new = 0.2437892518701269\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9917 episode and 2 step\n",
            "Delta Q = 0.9249494205456191\n",
            "Q_table[0,2]_old = 0.24778617426966565\n",
            "Q_table[(0, 2)]_new = 0.24795697738831815\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9917 episode and 3 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.23551247052440902\n",
            "Q_table[(1, 1)]_new = 0.23577747510129554\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9917 episode and 4 step\n",
            "Delta Q = 0.9221749227100935\n",
            "Q_table[6,1]_old = 0.21605915500359657\n",
            "Q_table[(6, 1)]_new = 0.21662816221333037\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9917 episode and 5 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[11,3]_old = 0.22398911828377213\n",
            "Q_table[(11, 3)]_new = 0.22540645808472234\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9917 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9918 episode and 0 step\n",
            "Delta Q = 0.9245477407614435\n",
            "Q_table[0,3]_old = 0.24440791097223724\n",
            "Q_table[(0, 3)]_new = 0.24451486063645703\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9918 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9919 episode and 0 step\n",
            "Delta Q = 0.9245477407614435\n",
            "Q_table[0,0]_old = 0.2437892518701269\n",
            "Q_table[(0, 0)]_new = 0.24395806744455772\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9919 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9920 episode and 0 step\n",
            "Delta Q = 0.9249494205456191\n",
            "Q_table[0,2]_old = 0.24795697738831815\n",
            "Q_table[(0, 2)]_new = 0.2481107001951054\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9920 episode and 1 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.23577747510129554\n",
            "Q_table[(1, 1)]_new = 0.23601597922049342\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9920 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 0 step\n",
            "Delta Q = 0.9245629593193154\n",
            "Q_table[0,3]_old = 0.24451486063645703\n",
            "Q_table[(0, 3)]_new = 0.24462633389212676\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 1 step\n",
            "Delta Q = 0.9245629593193154\n",
            "Q_table[0,0]_old = 0.24395806744455772\n",
            "Q_table[(0, 0)]_new = 0.2441252200194174\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 2 step\n",
            "Delta Q = 0.9245629593193154\n",
            "Q_table[0,0]_old = 0.2441252200194174\n",
            "Q_table[(0, 0)]_new = 0.24427565733679107\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 3 step\n",
            "Delta Q = 0.9249494205456191\n",
            "Q_table[0,2]_old = 0.2481107001951054\n",
            "Q_table[(0, 2)]_new = 0.24824905072121392\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 4 step\n",
            "Delta Q = 0.925603306834502\n",
            "Q_table[1,2]_old = 0.252014348945647\n",
            "Q_table[(1, 2)]_new = 0.25241622088558424\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 5 step\n",
            "Delta Q = 0.9264382569819865\n",
            "Q_table[2,2]_old = 0.2586192609545653\n",
            "Q_table[(2, 2)]_new = 0.25919559184109514\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 6 step\n",
            "Delta Q = 0.9264382569819865\n",
            "Q_table[3,3]_old = 0.24461346972160952\n",
            "Q_table[(3, 3)]_new = 0.24659037973143497\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 7 step\n",
            "Delta Q = 0.9283094635636753\n",
            "Q_table[3,1]_old = 0.2670531008281454\n",
            "Q_table[(3, 1)]_new = 0.26865725430900605\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9921 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 0 step\n",
            "Delta Q = 0.9245766560214002\n",
            "Q_table[0,3]_old = 0.24462633389212676\n",
            "Q_table[(0, 3)]_new = 0.24474035652431428\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 1 step\n",
            "Delta Q = 0.9245766560214002\n",
            "Q_table[0,0]_old = 0.24427565733679107\n",
            "Q_table[(0, 0)]_new = 0.24442474762451216\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 2 step\n",
            "Delta Q = 0.9245766560214002\n",
            "Q_table[0,0]_old = 0.24442474762451216\n",
            "Q_table[(0, 0)]_new = 0.24455892888346115\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 3 step\n",
            "Delta Q = 0.9245766560214002\n",
            "Q_table[0,3]_old = 0.24474035652431428\n",
            "Q_table[(0, 3)]_new = 0.24484297689328305\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 4 step\n",
            "Delta Q = 0.9249892058676729\n",
            "Q_table[0,2]_old = 0.24824905072121392\n",
            "Q_table[(0, 2)]_new = 0.24841335151676536\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 5 step\n",
            "Delta Q = 0.9249892058676729\n",
            "Q_table[1,3]_old = 0.24525520144506266\n",
            "Q_table[(1, 3)]_new = 0.24571888716822923\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 6 step\n",
            "Delta Q = 0.9256603635922684\n",
            "Q_table[1,2]_old = 0.25241622088558424\n",
            "Q_table[(1, 2)]_new = 0.25283496238929426\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 7 step\n",
            "Delta Q = 0.9250306612765402\n",
            "Q_table[2,0]_old = 0.24036873048836457\n",
            "Q_table[(2, 0)]_new = 0.24136251871606826\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 8 step\n",
            "Delta Q = 0.9250306612765402\n",
            "Q_table[1,3]_old = 0.24571888716822923\n",
            "Q_table[(1, 3)]_new = 0.24617765972794645\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 9 step\n",
            "Delta Q = 0.9250306612765402\n",
            "Q_table[1,3]_old = 0.24617765972794645\n",
            "Q_table[(1, 3)]_new = 0.24659055503169194\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 10 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.23601597922049342\n",
            "Q_table[(1, 1)]_new = 0.23623063292777152\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 11 step\n",
            "Delta Q = 0.9223152393503875\n",
            "Q_table[6,1]_old = 0.21662816221333037\n",
            "Q_table[(6, 1)]_new = 0.21728058534238484\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 12 step\n",
            "Delta Q = 0.9167133885304355\n",
            "Q_table[11,2]_old = 0.14896492992481322\n",
            "Q_table[(11, 2)]_new = 0.15078182546276733\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 13 step\n",
            "Delta Q = 0.9144185374079259\n",
            "Q_table[12,1]_old = 0.08795756289451766\n",
            "Q_table[(12, 1)]_new = 0.09358034401299178\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 14 step\n",
            "Delta Q = 0.9281432088865225\n",
            "Q_table[17,2]_old = 0.14564179199925145\n",
            "Q_table[(17, 2)]_new = 0.15922082168584872\n",
            "We are on 17 state\n",
            "And now we are on 18 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 15 step\n",
            "Delta Q = 0.9099\n",
            "Q_table[18,1]_old = 0.040541490000000006\n",
            "Q_table[(18, 1)]_new = 0.046387341000000006\n",
            "We are on 18 state\n",
            "And now we are on 23 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 16 step\n",
            "Delta Q = 0.9099\n",
            "Q_table[23,1]_old = 0.0099\n",
            "Q_table[(23, 1)]_new = 0.01881\n",
            "We are on 23 state\n",
            "And now we are on 23 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 17 step\n",
            "Delta Q = 0.9099\n",
            "Q_table[23,1]_old = 0.01881\n",
            "Q_table[(23, 1)]_new = 0.026829\n",
            "We are on 23 state\n",
            "And now we are on 23 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9922 episode and 18 step\n",
            "Delta Q = 1.0\n",
            "Q_table[23,2]_old = 0.1\n",
            "Q_table[(23, 2)]_new = 0.19\n",
            "We are on 23 state\n",
            "And now we are on 24 state\n",
            "We get 1.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9923 episode and 0 step\n",
            "Delta Q = 0.9245929218001598\n",
            "Q_table[0,3]_old = 0.24484297689328305\n",
            "Q_table[(0, 3)]_new = 0.2449516010041145\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9923 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9924 episode and 0 step\n",
            "Delta Q = 0.9245929218001598\n",
            "Q_table[0,0]_old = 0.24455892888346115\n",
            "Q_table[(0, 0)]_new = 0.2446959577952748\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9924 episode and 1 step\n",
            "Delta Q = 0.9245929218001598\n",
            "Q_table[0,0]_old = 0.2446959577952748\n",
            "Q_table[(0, 0)]_new = 0.2448192838159071\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9924 episode and 2 step\n",
            "Delta Q = 0.9250306612765402\n",
            "Q_table[0,2]_old = 0.24841335151676536\n",
            "Q_table[(0, 2)]_new = 0.24860267764162897\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9924 episode and 3 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.23623063292777152\n",
            "Q_table[(1, 1)]_new = 0.23642382126432182\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9924 episode and 4 step\n",
            "Delta Q = 0.9223152393503875\n",
            "Q_table[6,1]_old = 0.21728058534238484\n",
            "Q_table[(6, 1)]_new = 0.21786776615853387\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9924 episode and 5 step\n",
            "Delta Q = 0.9157644774081422\n",
            "Q_table[11,0]_old = 0.1390594065407742\n",
            "Q_table[(11, 0)]_new = 0.14091794329483887\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9924 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,3]_old = 0.0\n",
            "Q_table[(10, 3)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9925 episode and 0 step\n",
            "Delta Q = 0.9250306612765402\n",
            "Q_table[0,2]_old = 0.24860267764162897\n",
            "Q_table[(0, 2)]_new = 0.2487730711540062\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9925 episode and 1 step\n",
            "Delta Q = 0.9256603635922684\n",
            "Q_table[1,2]_old = 0.25283496238929426\n",
            "Q_table[(1, 2)]_new = 0.25321182974263323\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9925 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 0 step\n",
            "Delta Q = 0.9246285340442466\n",
            "Q_table[0,3]_old = 0.2449516010041145\n",
            "Q_table[(0, 3)]_new = 0.24508497494794967\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 1 step\n",
            "Delta Q = 0.9250679711445207\n",
            "Q_table[0,2]_old = 0.2487730711540062\n",
            "Q_table[(0, 2)]_new = 0.24896373518312628\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 2 step\n",
            "Delta Q = 0.9246474097831295\n",
            "Q_table[1,0]_old = 0.24236159339807004\n",
            "Q_table[(1, 0)]_new = 0.24277284384139253\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 3 step\n",
            "Delta Q = 0.9246474097831295\n",
            "Q_table[0,3]_old = 0.24508497494794967\n",
            "Q_table[(0, 3)]_new = 0.2452238872362842\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 4 step\n",
            "Delta Q = 0.9246474097831295\n",
            "Q_table[0,0]_old = 0.2448192838159071\n",
            "Q_table[(0, 0)]_new = 0.2449847652174459\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 5 step\n",
            "Delta Q = 0.9250679711445207\n",
            "Q_table[0,2]_old = 0.24896373518312628\n",
            "Q_table[(0, 2)]_new = 0.24913533280933436\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 6 step\n",
            "Delta Q = 0.9246643979481242\n",
            "Q_table[1,0]_old = 0.24277284384139253\n",
            "Q_table[(1, 0)]_new = 0.24315995740537738\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 7 step\n",
            "Delta Q = 0.9246643979481242\n",
            "Q_table[0,0]_old = 0.2449847652174459\n",
            "Q_table[(0, 0)]_new = 0.24515068664382542\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 8 step\n",
            "Delta Q = 0.9250679711445207\n",
            "Q_table[0,2]_old = 0.24913533280933436\n",
            "Q_table[(0, 2)]_new = 0.24928977067292163\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 9 step\n",
            "Delta Q = 0.9250679711445207\n",
            "Q_table[1,3]_old = 0.24659055503169194\n",
            "Q_table[(1, 3)]_new = 0.24699947067304345\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 10 step\n",
            "Delta Q = 0.9256603635922684\n",
            "Q_table[1,2]_old = 0.25321182974263323\n",
            "Q_table[(1, 2)]_new = 0.2535510103606383\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9926 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9927 episode and 0 step\n",
            "Delta Q = 0.9246796872966193\n",
            "Q_table[0,3]_old = 0.2452238872362842\n",
            "Q_table[(0, 3)]_new = 0.245381185809275\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9927 episode and 1 step\n",
            "Delta Q = 0.9251015500257033\n",
            "Q_table[0,2]_old = 0.24928977067292163\n",
            "Q_table[(0, 2)]_new = 0.24946234363133266\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9927 episode and 2 step\n",
            "Delta Q = 0.9251015500257033\n",
            "Q_table[1,3]_old = 0.24699947067304345\n",
            "Q_table[(1, 3)]_new = 0.24740107363144231\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9927 episode and 3 step\n",
            "Delta Q = 0.9251015500257033\n",
            "Q_table[1,3]_old = 0.24740107363144231\n",
            "Q_table[(1, 3)]_new = 0.24776251629400128\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9927 episode and 4 step\n",
            "Delta Q = 0.924696772019502\n",
            "Q_table[1,0]_old = 0.24315995740537738\n",
            "Q_table[(1, 0)]_new = 0.2435407336843416\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9927 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9928 episode and 0 step\n",
            "Delta Q = 0.9251015500257033\n",
            "Q_table[0,2]_old = 0.24946234363133266\n",
            "Q_table[(0, 2)]_new = 0.2496176592939026\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9928 episode and 1 step\n",
            "Delta Q = 0.9256603635922684\n",
            "Q_table[1,2]_old = 0.2535510103606383\n",
            "Q_table[(1, 2)]_new = 0.2538562729168429\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9928 episode and 2 step\n",
            "Delta Q = 0.9265970681765916\n",
            "Q_table[2,2]_old = 0.25919559184109514\n",
            "Q_table[(2, 2)]_new = 0.25987310083357723\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9928 episode and 3 step\n",
            "Delta Q = 0.9283094635636753\n",
            "Q_table[3,1]_old = 0.26865725430900605\n",
            "Q_table[(3, 1)]_new = 0.27010099244178065\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9928 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 0 step\n",
            "Delta Q = 0.9247121482700964\n",
            "Q_table[0,0]_old = 0.24515068664382542\n",
            "Q_table[(0, 0)]_new = 0.24534776624953922\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 1 step\n",
            "Delta Q = 0.9247121482700964\n",
            "Q_table[0,3]_old = 0.245381185809275\n",
            "Q_table[(0, 3)]_new = 0.24555521549844386\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 2 step\n",
            "Delta Q = 0.9247121482700964\n",
            "Q_table[0,3]_old = 0.24555521549844386\n",
            "Q_table[(0, 3)]_new = 0.24571184221869583\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 3 step\n",
            "Delta Q = 0.9251317710187674\n",
            "Q_table[0,2]_old = 0.2496176592939026\n",
            "Q_table[(0, 2)]_new = 0.2497876643832798\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 4 step\n",
            "Delta Q = 0.9238162516293275\n",
            "Q_table[1,1]_old = 0.23642382126432182\n",
            "Q_table[(1, 1)]_new = 0.23659769076721707\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 5 step\n",
            "Delta Q = 0.9251317710187674\n",
            "Q_table[6,3]_old = 0.24056819827603476\n",
            "Q_table[(6, 3)]_new = 0.24164314946719875\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 6 step\n",
            "Delta Q = 0.9239226717972527\n",
            "Q_table[1,1]_old = 0.23659769076721707\n",
            "Q_table[(1, 1)]_new = 0.23686059348774804\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9929 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9930 episode and 0 step\n",
            "Delta Q = 0.9247289787739448\n",
            "Q_table[0,3]_old = 0.24571184221869583\n",
            "Q_table[(0, 3)]_new = 0.24586963677077095\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9930 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9931 episode and 0 step\n",
            "Delta Q = 0.9247289787739448\n",
            "Q_table[0,0]_old = 0.24534776624953922\n",
            "Q_table[(0, 0)]_new = 0.24554196839853\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9931 episode and 1 step\n",
            "Delta Q = 0.9251317710187674\n",
            "Q_table[0,2]_old = 0.2497876643832798\n",
            "Q_table[(0, 2)]_new = 0.24994066896371928\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9931 episode and 2 step\n",
            "Delta Q = 0.9239226717972527\n",
            "Q_table[1,1]_old = 0.23686059348774804\n",
            "Q_table[(1, 1)]_new = 0.23709720593622594\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9931 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9932 episode and 0 step\n",
            "Delta Q = 0.9247441262274082\n",
            "Q_table[0,0]_old = 0.24554196839853\n",
            "Q_table[(0, 0)]_new = 0.2457318977860852\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9932 episode and 1 step\n",
            "Delta Q = 0.9247441262274082\n",
            "Q_table[0,3]_old = 0.24586963677077095\n",
            "Q_table[(0, 3)]_new = 0.24602679932110208\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9932 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9933 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9934 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9935 episode and 0 step\n",
            "Delta Q = 0.9247441262274082\n",
            "Q_table[0,3]_old = 0.24602679932110208\n",
            "Q_table[(0, 3)]_new = 0.24616824561640008\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9935 episode and 1 step\n",
            "Delta Q = 0.9247441262274082\n",
            "Q_table[0,0]_old = 0.2457318977860852\n",
            "Q_table[(0, 0)]_new = 0.2459028342348849\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9935 episode and 2 step\n",
            "Delta Q = 0.9247441262274082\n",
            "Q_table[0,0]_old = 0.2459028342348849\n",
            "Q_table[(0, 0)]_new = 0.24605667703880463\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9935 episode and 3 step\n",
            "Delta Q = 0.9251317710187674\n",
            "Q_table[0,2]_old = 0.24994066896371928\n",
            "Q_table[(0, 2)]_new = 0.2500783730861148\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9935 episode and 4 step\n",
            "Delta Q = 0.9239226717972527\n",
            "Q_table[1,1]_old = 0.23709720593622594\n",
            "Q_table[(1, 1)]_new = 0.23731015713985604\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9935 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 0 step\n",
            "Delta Q = 0.9251317710187674\n",
            "Q_table[0,2]_old = 0.2500783730861148\n",
            "Q_table[(0, 2)]_new = 0.25020230679627076\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 1 step\n",
            "Delta Q = 0.9239226717972527\n",
            "Q_table[1,1]_old = 0.23731015713985604\n",
            "Q_table[(1, 1)]_new = 0.23750181322312314\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 2 step\n",
            "Delta Q = 0.9251317710187674\n",
            "Q_table[6,3]_old = 0.24164314946719875\n",
            "Q_table[(6, 3)]_new = 0.24261060553924635\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 3 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[1,2]_old = 0.2538562729168429\n",
            "Q_table[(1, 2)]_new = 0.25419808260768273\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 4 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.2477824240557483\n",
            "Q_table[(2, 3)]_new = 0.2487316186326976\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 5 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.2487316186326976\n",
            "Q_table[(2, 3)]_new = 0.24958589375195198\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 6 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.24958589375195198\n",
            "Q_table[(2, 3)]_new = 0.25035474135928093\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 7 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.25035474135928093\n",
            "Q_table[(2, 3)]_new = 0.251046704205877\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 8 step\n",
            "Delta Q = 0.9251656101781606\n",
            "Q_table[2,0]_old = 0.24136251871606826\n",
            "Q_table[(2, 0)]_new = 0.24239187702262205\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 9 step\n",
            "Delta Q = 0.9251656101781606\n",
            "Q_table[1,3]_old = 0.24776251629400128\n",
            "Q_table[(1, 3)]_new = 0.24815187484276177\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 10 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[1,2]_old = 0.25419808260768273\n",
            "Q_table[(1, 2)]_new = 0.2545057113294386\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 11 step\n",
            "Delta Q = 0.9251960654216145\n",
            "Q_table[2,0]_old = 0.24239187702262205\n",
            "Q_table[(2, 0)]_new = 0.2433487547419743\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 12 step\n",
            "Delta Q = 0.9240184499483854\n",
            "Q_table[1,1]_old = 0.23750181322312314\n",
            "Q_table[(1, 1)]_new = 0.23777008184919624\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9936 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9937 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 0 step\n",
            "Delta Q = 0.9251960654216145\n",
            "Q_table[0,2]_old = 0.25020230679627076\n",
            "Q_table[(0, 2)]_new = 0.2503781415382581\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 1 step\n",
            "Delta Q = 0.9247874360122876\n",
            "Q_table[1,0]_old = 0.2435407336843416\n",
            "Q_table[(1, 0)]_new = 0.243974096328195\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 2 step\n",
            "Delta Q = 0.9251960654216145\n",
            "Q_table[0,2]_old = 0.2503781415382581\n",
            "Q_table[(0, 2)]_new = 0.2505363928060467\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 3 step\n",
            "Delta Q = 0.9251960654216145\n",
            "Q_table[1,3]_old = 0.24815187484276177\n",
            "Q_table[(1, 3)]_new = 0.24853275278010004\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 4 step\n",
            "Delta Q = 0.9248031028877987\n",
            "Q_table[1,0]_old = 0.243974096328195\n",
            "Q_table[(1, 0)]_new = 0.24437978958317413\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 5 step\n",
            "Delta Q = 0.9248031028877987\n",
            "Q_table[0,0]_old = 0.24605667703880463\n",
            "Q_table[(0, 0)]_new = 0.2462541122227228\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 6 step\n",
            "Delta Q = 0.9248031028877987\n",
            "Q_table[0,0]_old = 0.2462541122227228\n",
            "Q_table[(0, 0)]_new = 0.24643180388824917\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 7 step\n",
            "Delta Q = 0.9251960654216145\n",
            "Q_table[0,2]_old = 0.2505363928060467\n",
            "Q_table[(0, 2)]_new = 0.25067881894705646\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 8 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[1,2]_old = 0.2545057113294386\n",
            "Q_table[(1, 2)]_new = 0.2547825771790189\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 9 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.251046704205877\n",
            "Q_table[(2, 3)]_new = 0.25166947076781343\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 10 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.25166947076781343\n",
            "Q_table[(2, 3)]_new = 0.25222996067355624\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 11 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.25222996067355624\n",
            "Q_table[(2, 3)]_new = 0.2527344015887248\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9938 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9939 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9940 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9941 episode and 0 step\n",
            "Delta Q = 0.9252234751407229\n",
            "Q_table[0,2]_old = 0.25067881894705646\n",
            "Q_table[(0, 2)]_new = 0.2508344121930737\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9941 episode and 1 step\n",
            "Delta Q = 0.9248326068071143\n",
            "Q_table[1,0]_old = 0.24437978958317413\n",
            "Q_table[(1, 0)]_new = 0.24477441743197104\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9941 episode and 2 step\n",
            "Delta Q = 0.9252234751407229\n",
            "Q_table[0,2]_old = 0.2508344121930737\n",
            "Q_table[(0, 2)]_new = 0.25097444611448916\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9941 episode and 3 step\n",
            "Delta Q = 0.9252234751407229\n",
            "Q_table[1,3]_old = 0.24853275278010004\n",
            "Q_table[(1, 3)]_new = 0.2489029526428129\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9941 episode and 4 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[1,2]_old = 0.2547825771790189\n",
            "Q_table[(1, 2)]_new = 0.2550317564436412\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9941 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9942 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 0 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,3]_old = 0.24616824561640008\n",
            "Q_table[(0, 3)]_new = 0.2463978912200945\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 1 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,0]_old = 0.24643180388824917\n",
            "Q_table[(0, 0)]_new = 0.2466350936647587\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 2 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,0]_old = 0.2466350936647587\n",
            "Q_table[(0, 0)]_new = 0.24681805446361724\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 3 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,0]_old = 0.24681805446361724\n",
            "Q_table[(0, 0)]_new = 0.24698271918258993\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 4 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,3]_old = 0.2463978912200945\n",
            "Q_table[(0, 3)]_new = 0.24660457226341947\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 5 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,3]_old = 0.24660457226341947\n",
            "Q_table[(0, 3)]_new = 0.24679058520241196\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 6 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,3]_old = 0.24679058520241196\n",
            "Q_table[(0, 3)]_new = 0.2469579968475052\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 7 step\n",
            "Delta Q = 0.9248464701653345\n",
            "Q_table[0,0]_old = 0.24698271918258993\n",
            "Q_table[(0, 0)]_new = 0.24713091742966536\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9943 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9944 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 0 step\n",
            "Delta Q = 0.9252481438879205\n",
            "Q_table[0,2]_old = 0.25097444611448916\n",
            "Q_table[(0, 2)]_new = 0.2511251453909607\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 1 step\n",
            "Delta Q = 0.9252481438879205\n",
            "Q_table[1,3]_old = 0.2489029526428129\n",
            "Q_table[(1, 3)]_new = 0.2492608012664521\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 2 step\n",
            "Delta Q = 0.9248613893937051\n",
            "Q_table[1,0]_old = 0.24477441743197104\n",
            "Q_table[(1, 0)]_new = 0.24515836508247904\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 3 step\n",
            "Delta Q = 0.9252481438879205\n",
            "Q_table[0,2]_old = 0.2511251453909607\n",
            "Q_table[(0, 2)]_new = 0.2512607747397851\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 4 step\n",
            "Delta Q = 0.9248748166992388\n",
            "Q_table[1,0]_old = 0.24515836508247904\n",
            "Q_table[(1, 0)]_new = 0.24551734527346986\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 5 step\n",
            "Delta Q = 0.9248748166992388\n",
            "Q_table[0,3]_old = 0.2469579968475052\n",
            "Q_table[(0, 3)]_new = 0.24713701386199338\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 6 step\n",
            "Delta Q = 0.9252481438879205\n",
            "Q_table[0,2]_old = 0.2512607747397851\n",
            "Q_table[(0, 2)]_new = 0.25138284115372705\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 7 step\n",
            "Delta Q = 0.9240184499483854\n",
            "Q_table[1,1]_old = 0.23777008184919624\n",
            "Q_table[(1, 1)]_new = 0.238011523612662\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 8 step\n",
            "Delta Q = 0.9252481438879205\n",
            "Q_table[6,3]_old = 0.24261060553924635\n",
            "Q_table[(6, 3)]_new = 0.2435976888732422\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 9 step\n",
            "Delta Q = 0.924886901274219\n",
            "Q_table[1,0]_old = 0.24551734527346986\n",
            "Q_table[(1, 0)]_new = 0.24585251202034183\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 10 step\n",
            "Delta Q = 0.924886901274219\n",
            "Q_table[0,0]_old = 0.24713091742966536\n",
            "Q_table[(0, 0)]_new = 0.2473047269609178\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9945 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9946 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 0 step\n",
            "Delta Q = 0.924886901274219\n",
            "Q_table[0,3]_old = 0.24713701386199338\n",
            "Q_table[(0, 3)]_new = 0.24731021375001302\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 1 step\n",
            "Delta Q = 0.924886901274219\n",
            "Q_table[0,0]_old = 0.2473047269609178\n",
            "Q_table[(0, 0)]_new = 0.247461155539045\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 2 step\n",
            "Delta Q = 0.9252481438879205\n",
            "Q_table[0,2]_old = 0.25138284115372705\n",
            "Q_table[(0, 2)]_new = 0.25149270092627485\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 3 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[1,2]_old = 0.2550317564436412\n",
            "Q_table[(1, 2)]_new = 0.25525601778180124\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 4 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.2527344015887248\n",
            "Q_table[(2, 3)]_new = 0.25318839841237645\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 5 step\n",
            "Delta Q = 0.9257274369825241\n",
            "Q_table[2,3]_old = 0.25318839841237645\n",
            "Q_table[(2, 3)]_new = 0.25359699555366294\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 6 step\n",
            "Delta Q = 0.9267399982517364\n",
            "Q_table[2,2]_old = 0.25987310083357723\n",
            "Q_table[(2, 2)]_new = 0.26062578900195577\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 7 step\n",
            "Delta Q = 0.9267399982517364\n",
            "Q_table[3,3]_old = 0.24659037973143497\n",
            "Q_table[(3, 3)]_new = 0.24867134001002775\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 8 step\n",
            "Delta Q = 0.9283094635636753\n",
            "Q_table[3,1]_old = 0.27010099244178065\n",
            "Q_table[(3, 1)]_new = 0.27140035676127783\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9947 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9948 episode and 0 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,0]_old = 0.247461155539045\n",
            "Q_table[(0, 0)]_new = 0.2476128173768417\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9948 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9949 episode and 0 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,3]_old = 0.24731021375001302\n",
            "Q_table[(0, 3)]_new = 0.24747696976671293\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9949 episode and 1 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,3]_old = 0.24747696976671293\n",
            "Q_table[(0, 3)]_new = 0.24762705018174286\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9949 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9950 episode and 0 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,3]_old = 0.24762705018174286\n",
            "Q_table[(0, 3)]_new = 0.24776212255526978\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9950 episode and 1 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,3]_old = 0.24776212255526978\n",
            "Q_table[(0, 3)]_new = 0.247883687691444\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9950 episode and 2 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,3]_old = 0.247883687691444\n",
            "Q_table[(0, 3)]_new = 0.24799309631400082\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9950 episode and 3 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,3]_old = 0.24799309631400082\n",
            "Q_table[(0, 3)]_new = 0.24809156407430194\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9950 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9951 episode and 0 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,0]_old = 0.2476128173768417\n",
            "Q_table[(0, 0)]_new = 0.24774931303085876\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9951 episode and 1 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,0]_old = 0.24774931303085876\n",
            "Q_table[(0, 0)]_new = 0.2478721591194741\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9951 episode and 2 step\n",
            "Delta Q = 0.9248977773917012\n",
            "Q_table[0,3]_old = 0.24809156407430194\n",
            "Q_table[(0, 3)]_new = 0.24818018505857295\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9951 episode and 3 step\n",
            "Delta Q = 0.9252703457603983\n",
            "Q_table[0,2]_old = 0.25149270092627485\n",
            "Q_table[(0, 2)]_new = 0.25161377659404566\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9951 episode and 4 step\n",
            "Delta Q = 0.924116171198451\n",
            "Q_table[1,1]_old = 0.238011523612662\n",
            "Q_table[(1, 1)]_new = 0.23832654244984677\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9951 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 0 step\n",
            "Delta Q = 0.9249097638828105\n",
            "Q_table[0,0]_old = 0.2478721591194741\n",
            "Q_table[(0, 0)]_new = 0.24799470709033722\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 1 step\n",
            "Delta Q = 0.9252703457603983\n",
            "Q_table[0,2]_old = 0.25161377659404566\n",
            "Q_table[(0, 2)]_new = 0.2517227446950394\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 2 step\n",
            "Delta Q = 0.9249205517248089\n",
            "Q_table[1,0]_old = 0.24585251202034183\n",
            "Q_table[(1, 0)]_new = 0.24618781254311656\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 3 step\n",
            "Delta Q = 0.9252703457603983\n",
            "Q_table[0,2]_old = 0.2517227446950394\n",
            "Q_table[(0, 2)]_new = 0.2518208159859338\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 4 step\n",
            "Delta Q = 0.9258019531111936\n",
            "Q_table[1,2]_old = 0.25525601778180124\n",
            "Q_table[(1, 2)]_new = 0.25553236911481475\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 5 step\n",
            "Delta Q = 0.9252977045423667\n",
            "Q_table[2,0]_old = 0.2433487547419743\n",
            "Q_table[(2, 0)]_new = 0.2443115838101435\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 6 step\n",
            "Delta Q = 0.9258019531111936\n",
            "Q_table[1,2]_old = 0.25553236911481475\n",
            "Q_table[(1, 2)]_new = 0.25578108531452687\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 7 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[2,2]_old = 0.26062578900195577\n",
            "Q_table[(2, 2)]_new = 0.26143184542112674\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 8 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[3,3]_old = 0.24867134001002775\n",
            "Q_table[(3, 3)]_new = 0.2506728413283915\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 9 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[3,3]_old = 0.2506728413283915\n",
            "Q_table[(3, 3)]_new = 0.25247419251491887\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 10 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[3,3]_old = 0.25247419251491887\n",
            "Q_table[(3, 3)]_new = 0.2540954085827935\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 11 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[3,3]_old = 0.2540954085827935\n",
            "Q_table[(3, 3)]_new = 0.25555450304388067\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 12 step\n",
            "Delta Q = 0.9258817526966916\n",
            "Q_table[3,0]_old = 0.2380285242647458\n",
            "Q_table[(3, 0)]_new = 0.24010742453496278\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 13 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[2,2]_old = 0.26143184542112674\n",
            "Q_table[(2, 2)]_new = 0.2621572961983806\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9952 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 0 step\n",
            "Delta Q = 0.9249302607826074\n",
            "Q_table[0,3]_old = 0.24818018505857295\n",
            "Q_table[(0, 3)]_new = 0.24829242733532308\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 1 step\n",
            "Delta Q = 0.9249302607826074\n",
            "Q_table[0,0]_old = 0.24799470709033722\n",
            "Q_table[(0, 0)]_new = 0.24812549716391097\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 2 step\n",
            "Delta Q = 0.9249302607826074\n",
            "Q_table[0,3]_old = 0.24829242733532308\n",
            "Q_table[(0, 3)]_new = 0.24839344538439823\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 3 step\n",
            "Delta Q = 0.9253223274461382\n",
            "Q_table[0,2]_old = 0.2518208159859338\n",
            "Q_table[(0, 2)]_new = 0.2519610618334786\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 4 step\n",
            "Delta Q = 0.9249441451215143\n",
            "Q_table[1,0]_old = 0.24618781254311656\n",
            "Q_table[(1, 0)]_new = 0.24651317641031928\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 5 step\n",
            "Delta Q = 0.9249441451215143\n",
            "Q_table[0,3]_old = 0.24839344538439823\n",
            "Q_table[(0, 3)]_new = 0.2484982459674728\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 6 step\n",
            "Delta Q = 0.9249441451215143\n",
            "Q_table[0,0]_old = 0.24812549716391097\n",
            "Q_table[(0, 0)]_new = 0.24825709256903425\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 7 step\n",
            "Delta Q = 0.9249441451215143\n",
            "Q_table[0,0]_old = 0.24825709256903425\n",
            "Q_table[(0, 0)]_new = 0.24837552843364522\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 8 step\n",
            "Delta Q = 0.9253223274461382\n",
            "Q_table[0,2]_old = 0.2519610618334786\n",
            "Q_table[(0, 2)]_new = 0.25208728309626893\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 9 step\n",
            "Delta Q = 0.9259535723236397\n",
            "Q_table[1,2]_old = 0.25578108531452687\n",
            "Q_table[(1, 2)]_new = 0.25615654910671387\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9953 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9954 episode and 0 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[0,2]_old = 0.25208728309626893\n",
            "Q_table[(0, 2)]_new = 0.2522380531482067\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9954 episode and 1 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[1,3]_old = 0.2492608012664521\n",
            "Q_table[(1, 3)]_new = 0.24969421950137155\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9954 episode and 2 step\n",
            "Delta Q = 0.9249715672616725\n",
            "Q_table[1,0]_old = 0.24651317641031928\n",
            "Q_table[(1, 0)]_new = 0.2468334260309598\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9954 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 0 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[0,2]_old = 0.2522380531482067\n",
            "Q_table[(0, 2)]_new = 0.2523737461949507\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 1 step\n",
            "Delta Q = 0.924116171198451\n",
            "Q_table[1,1]_old = 0.23832654244984677\n",
            "Q_table[(1, 1)]_new = 0.23861005940331306\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 2 step\n",
            "Delta Q = 0.9223152393503875\n",
            "Q_table[6,1]_old = 0.21786776615853387\n",
            "Q_table[(6, 1)]_new = 0.218396228893068\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 3 step\n",
            "Delta Q = 0.924116171198451\n",
            "Q_table[11,3]_old = 0.22540645808472234\n",
            "Q_table[(11, 3)]_new = 0.22698198347470108\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 4 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[6,3]_old = 0.2435976888732422\n",
            "Q_table[(6, 3)]_new = 0.24459741834748266\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 5 step\n",
            "Delta Q = 0.9249850008733002\n",
            "Q_table[1,0]_old = 0.2468334260309598\n",
            "Q_table[(1, 0)]_new = 0.24713508430116393\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 6 step\n",
            "Delta Q = 0.9249850008733002\n",
            "Q_table[0,0]_old = 0.24837552843364522\n",
            "Q_table[(0, 0)]_new = 0.2485229764635808\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 7 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[0,2]_old = 0.2523737461949507\n",
            "Q_table[(0, 2)]_new = 0.2524958699370203\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 8 step\n",
            "Delta Q = 0.9242151444164008\n",
            "Q_table[1,1]_old = 0.23861005940331306\n",
            "Q_table[(1, 1)]_new = 0.23896419787938256\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9955 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9956 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9957 episode and 0 step\n",
            "Delta Q = 0.924997091123765\n",
            "Q_table[0,3]_old = 0.2484982459674728\n",
            "Q_table[(0, 3)]_new = 0.24864551249449052\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9957 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9958 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 0 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[0,2]_old = 0.2524958699370203\n",
            "Q_table[(0, 2)]_new = 0.2526057813048829\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 1 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[1,3]_old = 0.24969421950137155\n",
            "Q_table[(1, 3)]_new = 0.25008429591279907\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 2 step\n",
            "Delta Q = 0.9250079723491834\n",
            "Q_table[1,0]_old = 0.24713508430116393\n",
            "Q_table[(1, 0)]_new = 0.24742954822023097\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 3 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[0,2]_old = 0.2526057813048829\n",
            "Q_table[(0, 2)]_new = 0.2527047015359593\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 4 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[1,3]_old = 0.25008429591279907\n",
            "Q_table[(1, 3)]_new = 0.2504353646830838\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 5 step\n",
            "Delta Q = 0.9250177654520599\n",
            "Q_table[1,0]_old = 0.24742954822023097\n",
            "Q_table[(1, 0)]_new = 0.24770435885026784\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 6 step\n",
            "Delta Q = 0.9253594983615647\n",
            "Q_table[0,2]_old = 0.2527047015359593\n",
            "Q_table[(0, 2)]_new = 0.25279372974392805\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 7 step\n",
            "Delta Q = 0.9259535723236397\n",
            "Q_table[1,2]_old = 0.25615654910671387\n",
            "Q_table[(1, 2)]_new = 0.25649446651968216\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9959 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9960 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9961 episode and 0 step\n",
            "Delta Q = 0.9250265792446489\n",
            "Q_table[0,0]_old = 0.2485229764635808\n",
            "Q_table[(0, 0)]_new = 0.2486972580618716\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9961 episode and 1 step\n",
            "Delta Q = 0.9253929521854486\n",
            "Q_table[0,2]_old = 0.25279372974392805\n",
            "Q_table[(0, 2)]_new = 0.25290730895498376\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9961 episode and 2 step\n",
            "Delta Q = 0.9242151444164008\n",
            "Q_table[1,1]_old = 0.23896419787938256\n",
            "Q_table[(1, 1)]_new = 0.2392829225078451\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9961 episode and 3 step\n",
            "Delta Q = 0.9224712163639954\n",
            "Q_table[6,1]_old = 0.218396228893068\n",
            "Q_table[(6, 1)]_new = 0.2190278223677566\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9961 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,1]_old = 0.0\n",
            "Q_table[(11, 1)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9962 episode and 0 step\n",
            "Delta Q = 0.9250378235865434\n",
            "Q_table[0,0]_old = 0.2486972580618716\n",
            "Q_table[(0, 0)]_new = 0.24886535584222783\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9962 episode and 1 step\n",
            "Delta Q = 0.9250378235865434\n",
            "Q_table[0,0]_old = 0.24886535584222783\n",
            "Q_table[(0, 0)]_new = 0.24901664384454844\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9962 episode and 2 step\n",
            "Delta Q = 0.9250378235865434\n",
            "Q_table[0,0]_old = 0.24901664384454844\n",
            "Q_table[(0, 0)]_new = 0.24915280304663698\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9962 episode and 3 step\n",
            "Delta Q = 0.9250378235865434\n",
            "Q_table[0,0]_old = 0.24915280304663698\n",
            "Q_table[(0, 0)]_new = 0.24927534632851667\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9962 episode and 4 step\n",
            "Delta Q = 0.9250378235865434\n",
            "Q_table[0,3]_old = 0.24864551249449052\n",
            "Q_table[(0, 3)]_new = 0.24881878483158484\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9962 episode and 5 step\n",
            "Delta Q = 0.9250378235865434\n",
            "Q_table[0,3]_old = 0.24881878483158484\n",
            "Q_table[(0, 3)]_new = 0.24897472993496975\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9962 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9963 episode and 0 step\n",
            "Delta Q = 0.9250378235865434\n",
            "Q_table[0,3]_old = 0.24897472993496975\n",
            "Q_table[(0, 3)]_new = 0.24911508052801615\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9963 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 0 step\n",
            "Delta Q = 0.9253929521854486\n",
            "Q_table[0,2]_old = 0.25290730895498376\n",
            "Q_table[(0, 2)]_new = 0.2530095302449339\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 1 step\n",
            "Delta Q = 0.9253929521854486\n",
            "Q_table[1,3]_old = 0.2504353646830838\n",
            "Q_table[(1, 3)]_new = 0.25078478040022395\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 2 step\n",
            "Delta Q = 0.9242151444164008\n",
            "Q_table[1,1]_old = 0.2392829225078451\n",
            "Q_table[(1, 1)]_new = 0.2395697746734614\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 3 step\n",
            "Delta Q = 0.9224712163639954\n",
            "Q_table[6,1]_old = 0.2190278223677566\n",
            "Q_table[(6, 1)]_new = 0.21959625649497636\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 4 step\n",
            "Delta Q = 0.9242151444164008\n",
            "Q_table[11,3]_old = 0.22698198347470108\n",
            "Q_table[(11, 3)]_new = 0.22849892954363177\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 5 step\n",
            "Delta Q = 0.9226213940248196\n",
            "Q_table[6,1]_old = 0.21959625649497636\n",
            "Q_table[(6, 1)]_new = 0.22025802487029827\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 6 step\n",
            "Delta Q = 0.9242151444164008\n",
            "Q_table[11,3]_old = 0.22849892954363177\n",
            "Q_table[(11, 3)]_new = 0.22986418100566935\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9964 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9965 episode and 0 step\n",
            "Delta Q = 0.9250479434942485\n",
            "Q_table[0,3]_old = 0.24911508052801615\n",
            "Q_table[(0, 3)]_new = 0.249251515969463\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9965 episode and 1 step\n",
            "Delta Q = 0.9250479434942485\n",
            "Q_table[0,3]_old = 0.249251515969463\n",
            "Q_table[(0, 3)]_new = 0.24937430786676515\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9965 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9966 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9967 episode and 0 step\n",
            "Delta Q = 0.9250479434942485\n",
            "Q_table[0,3]_old = 0.24937430786676515\n",
            "Q_table[(0, 3)]_new = 0.2494848205743371\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9967 episode and 1 step\n",
            "Delta Q = 0.9250479434942485\n",
            "Q_table[0,0]_old = 0.24927534632851667\n",
            "Q_table[(0, 0)]_new = 0.24939575518991347\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9967 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9968 episode and 0 step\n",
            "Delta Q = 0.9250479434942485\n",
            "Q_table[0,0]_old = 0.24939575518991347\n",
            "Q_table[(0, 0)]_new = 0.2495041231651706\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9968 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9969 episode and 0 step\n",
            "Delta Q = 0.9253929521854486\n",
            "Q_table[0,2]_old = 0.2530095302449339\n",
            "Q_table[(0, 2)]_new = 0.25310152940588904\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9969 episode and 1 step\n",
            "Delta Q = 0.9259535723236397\n",
            "Q_table[1,2]_old = 0.25649446651968216\n",
            "Q_table[(1, 2)]_new = 0.2567985921913536\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9969 episode and 2 step\n",
            "Delta Q = 0.925423060626944\n",
            "Q_table[2,0]_old = 0.2443115838101435\n",
            "Q_table[(2, 0)]_new = 0.24530348605607316\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9969 episode and 3 step\n",
            "Delta Q = 0.9242151444164008\n",
            "Q_table[1,1]_old = 0.2395697746734614\n",
            "Q_table[(1, 1)]_new = 0.23982794162251608\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9969 episode and 4 step\n",
            "Delta Q = 0.9227565539195612\n",
            "Q_table[6,1]_old = 0.22025802487029827\n",
            "Q_table[(6, 1)]_new = 0.22098877630282973\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9969 episode and 5 step\n",
            "Delta Q = 0.9167133885304355\n",
            "Q_table[11,2]_old = 0.15078182546276733\n",
            "Q_table[(11, 2)]_new = 0.15241703144692603\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9969 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,2]_old = 0.0\n",
            "Q_table[(12, 2)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 0 step\n",
            "Delta Q = 0.925057051411183\n",
            "Q_table[0,3]_old = 0.2494848205743371\n",
            "Q_table[(0, 3)]_new = 0.24959338992808638\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 1 step\n",
            "Delta Q = 0.925057051411183\n",
            "Q_table[0,3]_old = 0.24959338992808638\n",
            "Q_table[(0, 3)]_new = 0.24969110234646075\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 2 step\n",
            "Delta Q = 0.925057051411183\n",
            "Q_table[0,3]_old = 0.24969110234646075\n",
            "Q_table[(0, 3)]_new = 0.24977904352299768\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 3 step\n",
            "Delta Q = 0.925057051411183\n",
            "Q_table[0,3]_old = 0.24977904352299768\n",
            "Q_table[(0, 3)]_new = 0.2498581905818809\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 4 step\n",
            "Delta Q = 0.925057051411183\n",
            "Q_table[0,3]_old = 0.2498581905818809\n",
            "Q_table[(0, 3)]_new = 0.24992942293487586\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 5 step\n",
            "Delta Q = 0.925423060626944\n",
            "Q_table[0,2]_old = 0.25310152940588904\n",
            "Q_table[(0, 2)]_new = 0.25321443709224417\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 6 step\n",
            "Delta Q = 0.925423060626944\n",
            "Q_table[1,3]_old = 0.25078478040022395\n",
            "Q_table[(1, 3)]_new = 0.25112936298714555\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 7 step\n",
            "Delta Q = 0.9259535723236397\n",
            "Q_table[1,2]_old = 0.2567985921913536\n",
            "Q_table[(1, 2)]_new = 0.2570723052958579\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9970 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9971 episode and 0 step\n",
            "Delta Q = 0.92545015822429\n",
            "Q_table[0,2]_old = 0.25321443709224417\n",
            "Q_table[(0, 2)]_new = 0.2533431516073097\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9971 episode and 1 step\n",
            "Delta Q = 0.9242151444164008\n",
            "Q_table[1,1]_old = 0.23982794162251608\n",
            "Q_table[(1, 1)]_new = 0.24006029187666528\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9971 episode and 2 step\n",
            "Delta Q = 0.92545015822429\n",
            "Q_table[6,3]_old = 0.24459741834748266\n",
            "Q_table[(6, 3)]_new = 0.24558783473702434\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9971 episode and 3 step\n",
            "Delta Q = 0.9250809720091236\n",
            "Q_table[1,0]_old = 0.24770435885026784\n",
            "Q_table[(1, 0)]_new = 0.2480148949743647\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9971 episode and 4 step\n",
            "Delta Q = 0.9250809720091236\n",
            "Q_table[0,0]_old = 0.2495041231651706\n",
            "Q_table[(0, 0)]_new = 0.24963468285777718\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9971 episode and 5 step\n",
            "Delta Q = 0.9250809720091236\n",
            "Q_table[0,3]_old = 0.24992942293487586\n",
            "Q_table[(0, 3)]_new = 0.25001745265051195\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9971 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9972 episode and 0 step\n",
            "Delta Q = 0.92545015822429\n",
            "Q_table[0,2]_old = 0.2533431516073097\n",
            "Q_table[(0, 2)]_new = 0.2534589946708687\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9972 episode and 1 step\n",
            "Delta Q = 0.9243131956389654\n",
            "Q_table[1,1]_old = 0.24006029187666528\n",
            "Q_table[(1, 1)]_new = 0.24036745832796416\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9972 episode and 2 step\n",
            "Delta Q = 0.9227565539195612\n",
            "Q_table[6,1]_old = 0.22098877630282973\n",
            "Q_table[(6, 1)]_new = 0.22164645259210802\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9972 episode and 3 step\n",
            "Delta Q = 0.9157644774081422\n",
            "Q_table[11,0]_old = 0.14091794329483887\n",
            "Q_table[(11, 0)]_new = 0.14259062637349706\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9972 episode and 4 step\n",
            "Delta Q = 0.9157644774081422\n",
            "Q_table[10,0]_old = 0.11607582454094761\n",
            "Q_table[(10, 0)]_new = 0.12023271949499495\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9972 episode and 5 step\n",
            "Delta Q = 0.9227565539195612\n",
            "Q_table[10,2]_old = 0.15923714553678878\n",
            "Q_table[(10, 2)]_new = 0.16606998490267116\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9972 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,1]_old = 0.0\n",
            "Q_table[(11, 1)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9973 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9974 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9975 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9976 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9977 episode and 0 step\n",
            "Delta Q = 0.92545015822429\n",
            "Q_table[0,2]_old = 0.2534589946708687\n",
            "Q_table[(0, 2)]_new = 0.25356325342807173\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9977 episode and 1 step\n",
            "Delta Q = 0.9251027620893791\n",
            "Q_table[1,0]_old = 0.2480148949743647\n",
            "Q_table[(1, 0)]_new = 0.24831616756630737\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9977 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9978 episode and 0 step\n",
            "Delta Q = 0.9251027620893791\n",
            "Q_table[0,3]_old = 0.25001745265051195\n",
            "Q_table[(0, 3)]_new = 0.25011846947483984\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9978 episode and 1 step\n",
            "Delta Q = 0.9251027620893791\n",
            "Q_table[0,0]_old = 0.24963468285777718\n",
            "Q_table[(0, 0)]_new = 0.24977397666137857\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9978 episode and 2 step\n",
            "Delta Q = 0.9251027620893791\n",
            "Q_table[0,0]_old = 0.24977397666137857\n",
            "Q_table[(0, 0)]_new = 0.2498993410846198\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9978 episode and 3 step\n",
            "Delta Q = 0.92545015822429\n",
            "Q_table[0,2]_old = 0.25356325342807173\n",
            "Q_table[(0, 2)]_new = 0.2536570863095545\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9978 episode and 4 step\n",
            "Delta Q = 0.9259535723236397\n",
            "Q_table[1,2]_old = 0.2570723052958579\n",
            "Q_table[(1, 2)]_new = 0.2573186470899118\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9978 episode and 5 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[2,2]_old = 0.2621572961983806\n",
            "Q_table[(2, 2)]_new = 0.26281020189790905\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9978 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9979 episode and 0 step\n",
            "Delta Q = 0.9251120515446459\n",
            "Q_table[0,0]_old = 0.2498993410846198\n",
            "Q_table[(0, 0)]_new = 0.2500214585208037\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9979 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9980 episode and 0 step\n",
            "Delta Q = 0.9251120515446459\n",
            "Q_table[0,3]_old = 0.25011846947483984\n",
            "Q_table[(0, 3)]_new = 0.25021867407200177\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9980 episode and 1 step\n",
            "Delta Q = 0.9251120515446459\n",
            "Q_table[0,0]_old = 0.2500214585208037\n",
            "Q_table[(0, 0)]_new = 0.25013136421336923\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9980 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9981 episode and 0 step\n",
            "Delta Q = 0.9251120515446459\n",
            "Q_table[0,0]_old = 0.25013136421336923\n",
            "Q_table[(0, 0)]_new = 0.2502302793366782\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9981 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9982 episode and 0 step\n",
            "Delta Q = 0.9254745460619013\n",
            "Q_table[0,2]_old = 0.2536570863095545\n",
            "Q_table[(0, 2)]_new = 0.25376592374050033\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9982 episode and 1 step\n",
            "Delta Q = 0.926018209987893\n",
            "Q_table[1,2]_old = 0.2573186470899118\n",
            "Q_table[(1, 2)]_new = 0.2576049923688136\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9982 episode and 2 step\n",
            "Delta Q = 0.9255028942445126\n",
            "Q_table[2,0]_old = 0.24530348605607316\n",
            "Q_table[(2, 0)]_new = 0.2462760316949784\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9982 episode and 3 step\n",
            "Delta Q = 0.9255028942445126\n",
            "Q_table[1,3]_old = 0.25112936298714555\n",
            "Q_table[(1, 3)]_new = 0.25151932093294355\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9982 episode and 4 step\n",
            "Delta Q = 0.9255028942445126\n",
            "Q_table[1,3]_old = 0.25151932093294355\n",
            "Q_table[(1, 3)]_new = 0.2518702830841617\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9982 episode and 5 step\n",
            "Delta Q = 0.926018209987893\n",
            "Q_table[1,2]_old = 0.2576049923688136\n",
            "Q_table[(1, 2)]_new = 0.25786270311982523\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9982 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9983 episode and 0 step\n",
            "Delta Q = 0.9251228264503095\n",
            "Q_table[0,0]_old = 0.2502302793366782\n",
            "Q_table[(0, 0)]_new = 0.2503300778533199\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9983 episode and 1 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[0,2]_old = 0.25376592374050033\n",
            "Q_table[(0, 2)]_new = 0.253917738975313\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9983 episode and 2 step\n",
            "Delta Q = 0.9243131956389654\n",
            "Q_table[1,1]_old = 0.24036745832796416\n",
            "Q_table[(1, 1)]_new = 0.24064390813413317\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9983 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9984 episode and 0 step\n",
            "Delta Q = 0.925137856158556\n",
            "Q_table[0,0]_old = 0.2503300778533199\n",
            "Q_table[(0, 0)]_new = 0.2504349262265439\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9984 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9985 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9986 episode and 0 step\n",
            "Delta Q = 0.925137856158556\n",
            "Q_table[0,3]_old = 0.25021867407200177\n",
            "Q_table[(0, 3)]_new = 0.2503346628233576\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9986 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9987 episode and 0 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[0,2]_old = 0.253917738975313\n",
            "Q_table[(0, 2)]_new = 0.2540543726866444\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9987 episode and 1 step\n",
            "Delta Q = 0.9251513828959779\n",
            "Q_table[1,0]_old = 0.24831616756630737\n",
            "Q_table[(1, 0)]_new = 0.24863593370565443\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9987 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9988 episode and 0 step\n",
            "Delta Q = 0.9251513828959779\n",
            "Q_table[0,3]_old = 0.2503346628233576\n",
            "Q_table[(0, 3)]_new = 0.2504525794369996\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9988 episode and 1 step\n",
            "Delta Q = 0.9251513828959779\n",
            "Q_table[0,3]_old = 0.2504525794369996\n",
            "Q_table[(0, 3)]_new = 0.2505587043892774\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9988 episode and 2 step\n",
            "Delta Q = 0.9251513828959779\n",
            "Q_table[0,3]_old = 0.2505587043892774\n",
            "Q_table[(0, 3)]_new = 0.2506542168463275\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9988 episode and 3 step\n",
            "Delta Q = 0.9251513828959779\n",
            "Q_table[0,3]_old = 0.2506542168463275\n",
            "Q_table[(0, 3)]_new = 0.25074017805767257\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9988 episode and 4 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[0,2]_old = 0.2540543726866444\n",
            "Q_table[(0, 2)]_new = 0.25417734302684264\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9988 episode and 5 step\n",
            "Delta Q = 0.9243131956389654\n",
            "Q_table[1,1]_old = 0.24064390813413317\n",
            "Q_table[(1, 1)]_new = 0.24089271295968528\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9988 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 0 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,0]_old = 0.2504349262265439\n",
            "Q_table[(0, 0)]_new = 0.25055499056354696\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 1 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,0]_old = 0.25055499056354696\n",
            "Q_table[(0, 0)]_new = 0.2506630484668497\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 2 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,0]_old = 0.2506630484668497\n",
            "Q_table[(0, 0)]_new = 0.2507603005798222\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 3 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,3]_old = 0.25074017805767257\n",
            "Q_table[(0, 3)]_new = 0.2508297172115627\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 4 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,0]_old = 0.2507603005798222\n",
            "Q_table[(0, 0)]_new = 0.2508478274814974\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 5 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,3]_old = 0.2508297172115627\n",
            "Q_table[(0, 3)]_new = 0.2509103024500639\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 6 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,0]_old = 0.2508478274814974\n",
            "Q_table[(0, 0)]_new = 0.2509266016930051\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9989 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9990 episode and 0 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,0]_old = 0.2509266016930051\n",
            "Q_table[(0, 0)]_new = 0.25099749848336206\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9990 episode and 1 step\n",
            "Delta Q = 0.9251635569596575\n",
            "Q_table[0,0]_old = 0.25099749848336206\n",
            "Q_table[(0, 0)]_new = 0.25106130559468326\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9990 episode and 2 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[0,2]_old = 0.25417734302684264\n",
            "Q_table[(0, 2)]_new = 0.25428801633302106\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9990 episode and 3 step\n",
            "Delta Q = 0.9243131956389654\n",
            "Q_table[1,1]_old = 0.24089271295968528\n",
            "Q_table[(1, 1)]_new = 0.24111663730268218\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9990 episode and 4 step\n",
            "Delta Q = 0.9227565539195612\n",
            "Q_table[6,1]_old = 0.22164645259210802\n",
            "Q_table[(6, 1)]_new = 0.2222383612524585\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9990 episode and 5 step\n",
            "Delta Q = 0.9243131956389654\n",
            "Q_table[11,3]_old = 0.22986418100566935\n",
            "Q_table[(11, 3)]_new = 0.23119095854406785\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9990 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9991 episode and 0 step\n",
            "Delta Q = 0.9251745136169691\n",
            "Q_table[0,3]_old = 0.2509103024500639\n",
            "Q_table[(0, 3)]_new = 0.2509937858220266\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9991 episode and 1 step\n",
            "Delta Q = 0.9251745136169691\n",
            "Q_table[0,0]_old = 0.25106130559468326\n",
            "Q_table[(0, 0)]_new = 0.25112968865218405\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9991 episode and 2 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[0,2]_old = 0.25428801633302106\n",
            "Q_table[(0, 2)]_new = 0.25438762230858164\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9991 episode and 3 step\n",
            "Delta Q = 0.9251843746085496\n",
            "Q_table[1,0]_old = 0.24863593370565443\n",
            "Q_table[(1, 0)]_new = 0.24895671494363858\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9991 episode and 4 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[0,2]_old = 0.25438762230858164\n",
            "Q_table[(0, 2)]_new = 0.2544772676865862\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9991 episode and 5 step\n",
            "Delta Q = 0.9243131956389654\n",
            "Q_table[1,1]_old = 0.24111663730268218\n",
            "Q_table[(1, 1)]_new = 0.24131816921137939\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9991 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9992 episode and 0 step\n",
            "Delta Q = 0.925193249500972\n",
            "Q_table[0,3]_old = 0.2509937858220266\n",
            "Q_table[(0, 3)]_new = 0.251087656740796\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9992 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9993 episode and 0 step\n",
            "Delta Q = 0.925193249500972\n",
            "Q_table[0,3]_old = 0.251087656740796\n",
            "Q_table[(0, 3)]_new = 0.2511721405676884\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9993 episode and 1 step\n",
            "Delta Q = 0.925193249500972\n",
            "Q_table[0,0]_old = 0.25112968865218405\n",
            "Q_table[(0, 0)]_new = 0.25120996928793765\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9993 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9994 episode and 0 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[0,2]_old = 0.2544772676865862\n",
            "Q_table[(0, 2)]_new = 0.25455794852679026\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9994 episode and 1 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[1,3]_old = 0.2518702830841617\n",
            "Q_table[(1, 3)]_new = 0.25221166238460824\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9994 episode and 2 step\n",
            "Delta Q = 0.9255284076088627\n",
            "Q_table[1,3]_old = 0.25221166238460824\n",
            "Q_table[(1, 3)]_new = 0.2525189037550101\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9994 episode and 3 step\n",
            "Delta Q = 0.926018209987893\n",
            "Q_table[1,2]_old = 0.25786270311982523\n",
            "Q_table[(1, 2)]_new = 0.2580946427957357\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9994 episode and 4 step\n",
            "Delta Q = 0.9268686353193665\n",
            "Q_table[2,2]_old = 0.26281020189790905\n",
            "Q_table[(2, 2)]_new = 0.26339781702748466\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9994 episode and 5 step\n",
            "Delta Q = 0.9283094635636753\n",
            "Q_table[3,1]_old = 0.27140035676127783\n",
            "Q_table[(3, 1)]_new = 0.27256978464882525\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9994 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 0 step\n",
            "Delta Q = 0.9255513696367779\n",
            "Q_table[0,2]_old = 0.25455794852679026\n",
            "Q_table[(0, 2)]_new = 0.2546535233108891\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 1 step\n",
            "Delta Q = 0.926076383885721\n",
            "Q_table[1,2]_old = 0.2580946427957357\n",
            "Q_table[(1, 2)]_new = 0.2583615624018831\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 2 step\n",
            "Delta Q = 0.9269844086802337\n",
            "Q_table[2,2]_old = 0.26339781702748466\n",
            "Q_table[(2, 2)]_new = 0.2640424440049699\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 3 step\n",
            "Delta Q = 0.9269844086802337\n",
            "Q_table[3,3]_old = 0.25555450304388067\n",
            "Q_table[(3, 3)]_new = 0.25698346141972633\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 4 step\n",
            "Delta Q = 0.926140201956492\n",
            "Q_table[3,0]_old = 0.24010742453496278\n",
            "Q_table[(3, 0)]_new = 0.24223688403795854\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 5 step\n",
            "Delta Q = 0.926140201956492\n",
            "Q_table[2,3]_old = 0.25359699555366294\n",
            "Q_table[(2, 3)]_new = 0.25437749795478865\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 6 step\n",
            "Delta Q = 0.9255777946777864\n",
            "Q_table[2,0]_old = 0.2462760316949784\n",
            "Q_table[(2, 0)]_new = 0.24722622320326698\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 7 step\n",
            "Delta Q = 0.926140201956492\n",
            "Q_table[1,2]_old = 0.2583615624018831\n",
            "Q_table[(1, 2)]_new = 0.25866560811818684\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9995 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9996 episode and 0 step\n",
            "Delta Q = 0.9256078952037006\n",
            "Q_table[0,2]_old = 0.2546535233108891\n",
            "Q_table[(0, 2)]_new = 0.2547960661835007\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9996 episode and 1 step\n",
            "Delta Q = 0.9256078952037006\n",
            "Q_table[1,3]_old = 0.2525189037550101\n",
            "Q_table[(1, 3)]_new = 0.2528749085832096\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9996 episode and 2 step\n",
            "Delta Q = 0.926140201956492\n",
            "Q_table[1,2]_old = 0.25866560811818684\n",
            "Q_table[(1, 2)]_new = 0.25893924926286016\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9996 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9997 episode and 0 step\n",
            "Delta Q = 0.9256349856770232\n",
            "Q_table[0,2]_old = 0.2547960661835007\n",
            "Q_table[(0, 2)]_new = 0.2549514452421738\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9997 episode and 1 step\n",
            "Delta Q = 0.9252401930789752\n",
            "Q_table[1,0]_old = 0.24895671494363858\n",
            "Q_table[(1, 0)]_new = 0.24930123652824993\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9997 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9998 episode and 0 step\n",
            "Delta Q = 0.9252401930789752\n",
            "Q_table[0,3]_old = 0.2511721405676884\n",
            "Q_table[(0, 3)]_new = 0.25129511958989476\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9998 episode and 1 step\n",
            "Delta Q = 0.9252401930789752\n",
            "Q_table[0,3]_old = 0.25129511958989476\n",
            "Q_table[(0, 3)]_new = 0.2514058007098805\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9998 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9999 episode and 0 step\n",
            "Delta Q = 0.9252401930789752\n",
            "Q_table[0,3]_old = 0.2514058007098805\n",
            "Q_table[(0, 3)]_new = 0.25150541371786767\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 9999 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKdXyTOWWeYX",
        "outputId": "7d50c81f-d9c5-4a7c-bc5c-a9967ce5dba7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import imageio\n"
      ],
      "metadata": {
        "id": "86h4LdWyWiQS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)\n",
        ""
      ],
      "metadata": {
        "id": "bJ7lBKxhWqxV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "URJFrQpKWvVa",
        "outputId": "56849660-1e25-4c8a-cefd-933646a2b970"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/imageio/plugins/pillow.py:409: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/gif": "R0lGODlhQAFAAYUAAP///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtJ6qsGOrPzu+/zK5/zK4/yy1/yip+dCcjoyhtE+kuDGh7zt9Tyyl9SWo/yKb9R53v891K6tRMOZFOa0vRY9NV5dEBok7DExohTo/XlIzPysrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BABkAAAALAAAAABAAUABAAj/AA0IHEiwoMGDCBMqXMiwocOHECNKnEixosWLGCsS2MixI4EAIAMAGEmypMmTKEOG9Mhyo8CWHVWinEmzpEqQMD2+zPkxZM2fKW/y5Lgzp0ygSEfeDDDUpYGhR5MCXdqUgECmVUFO9YmUKsyrVXtu1dpV6FcDWJuSrRn1p9eWYLOKdMt17MqzaaHOXQuAbFu2ZuGiDct35l+ab1nGVTsXcGHEgRUPlms3aWKdkxlXLqsy52K9Shv33VuXbme8YTe2fRx66VKbrgN8ZsyX9ejYq2PP1ltbNGzcpXHv5pnbMPDgujNzxOmReeqWsX8vHW4UufHjooUrp53dN0nsvV1T/4dZPCh26TfHQ7du/jh6lbudL8/7PKbr9yGvnuZ++vVo/Mjlh9Z+vJnlX3j3fQffgHfxd9eB3UWnoICREeeaajeFBiCCsjEoX30gzpcbhQRa6BWEG0YIkn4NFthfhv9NmGBrK3pIX3UnwsghjDR2WCGOBuqoon89svhhiCASeVuNMpa4HoqcBShQky2Sl6BtJykpIJVHsiQhliZpyWSPVT4ppGU83jYlmU1x4OabcMb5JmHJcXmjl1d6d52UBtjpoF96thfemks6iSeUdg3aJ5ldNpcnmiMSellLclYaJ53iLWonhEcBJ9WSShHKaJ6d4vZpp6IWaqqqo4KZJVcdhv8JHpmtBrpnqJrCBpOcE/Tq668ZZLDBBpa6aeKYmwpZqoSQ7pUqeKQtO2OUuMp6HquqHuaYs7lmSyqsqzZb7au7xvnruRMEO2yxHBwba6LQRjstUqnuGa+8StLbrb3x1vopAPUK2q+3rp4UMEu8onsuBAw3HOzDGVxwwbpzrgfwvgIDZ8LGJvj7acCv3gsos0mBbK3IHktlcoqeEmzrTAd7lLDCvjbsMMQRT0xsxXheXNq/JnHccbIF+1jwqUPOmxKLQAPG8su4/tw0bE9PxTQACL9J89YL2+y1ujsbK+LVU5ckdNVukV021URD3Zfaa2vYttUMxi0r2mxdnbWbXPf/PYHXXwsbdrtj98mctHLDtrEDjDuwcW+H2jrl4eAC+qpxujqK5eRYIR4j25crGDlNnGM4Mmmhpz7a6DAbfiOcXBdQAAK012677VwzHCycGF68ek+nJ67g4o0/3h3rKJUOvLzCN69g5vZt7rrpzH/+fFDQiyj59MvT6LxtkGu+/e8dwb617LenX3vuEOxesVYBk3wS8Y0XP7R0PRuMsfxxO8la/Epbm//0BMB89a9M/9NU+bR2LvXVTnYCEAD6HPjAAqDLfWLzXcjSND8T1K9+G9tg/kxSQA4e8EgJzJjbkIZCAu4vgGUbYPIUyBHz/YqCCICgBGeHwxxa8FwYJJzv/8CHr7lsDAMY+GDjkGg8GlkpPa7DHLaQ5kQzbYmItPrX6Z64IOuxzYBbqWLktrRAvjWwgrJLoxp5aLs1srGC6BJbrLCIrSMmUYkOYKIJtmhFJtERjHQRo/iuGKjTHe1uS+IiIaUISKclso+xKiMH0NVGN64xfW7E5A9/JceibIs5dkSiKEdJyhCqqiqehMyLpjYpwXDkk51bocBQ+ZSNwLJ3TWulZLBWw0n6aoK0i6Awd5i+YUZQh5o85iYnIDar1JIAtyRAKElJTT2yqSmp5BcugaZLzLxSlQ+S5QYb5U1bgpNyrPyRYHi5ETP2CpgIMCYxbydPZN5Oh7LjJOGc6f+oPW1kYyAAwQcGStCCDjSgprymZ565zZOxJJ2G6khRGoo/j0C0TOWcjz8tmkt1SrRP7WQg7SYozwhWsqTztN0w09erZk5ULO35pwkCatCafgCh9zslT15KxCNdlJxO6WdMOcpNjxKFoTAVIVG1aFSn8NJ8I+UhSk9aUngGU5gsZeY+X9qRDQI0oAK1aUHBCoKEymihOVGqlRxZUVfCRK0WgwxcM/pQh1aHrWc9y1N9absDHECeldThMK3qQ8LC06VI7erJvkpTsRKUrGYVJF2XKlmhSrGtkkmrXdcq181m9q2eHSH2QvvRvfaqr381ZmALUM83RtWwb0QsRpMqtJn/gkABCuhABxLA297yVre4xWkTqdQaFnG2su5KE6eMG1fkAklMy2KuaCOqSOUqKy5mVKlqKzjVwrJWAJV87RsZ1kkGHbe2AcWtbn3rW+AqQLh7TFpxzdvcR2JqWsul73RnW90RVU66lrWvXEiWX6xkt3aA5W5JxWvSCorXduQlnNGgxTEKUOC3HQiBhkPg2w2HYL0JsPDGGqodkXVzPngicXJM3FQMpTipBDMSixnz4h1RKKTFBC8av7vSHRN2sG+UnQQkEEHVyPg4Fb5wAnTr4Q5vGMQiNoGKM8Vi6qLYUVOejo1MTGMsw7jEVQaqi71s4xoZmAM5Xm2CxftjYcJT/8hEFoCR0cIvlQjNwrzdmG/1HGIKCO2QJLlKncHzYur9S9AqxE6hu/cxOif6OIvWVk2wi2YKCna7UVWmdtccTwHYbAADgJ+jx3mTOyuZz3k2AW+jPFyVjfpk94q01H6CaFJDS9aAHkmtYR0vXItT15NxEw4v3eNMp7TTnI7gp0Mtkl0nxdSp3rOq+3w2oDk7SlVu2rXhZWJtv7pZ2bZ2sDmAzzVyWo0Npmq61TdkUIfGmb9uTZLZ21tWx9fb8XYZtPBd1DDn22f9DjO+Q1pudGPau+s2dsJv1+4BvPsz/5o3vanNMQCRTjk/hSH/Ao3xjrbM1tvLS8YBuXFgY4Vhb/9OI4MPrnCsUtBmD4X4pzjm4ZpvuNqjurjIPR4uXktv5wEvecl9ptigaxyGRCcAyoOscoSz3IecTh/MLSpjcyKF5javOc4FRkIbWd1uTP1L1aEJdqN33SxlN3tJ4sKwCETgqpbkscs3bUzCVpJhRR/7sz3YuIOCdaAgzCmpz36atIf9Z3o3vFTylXjFY9s3bIeA2+Fuyagju+6uvWcB8P5Nn/l0tPRzgN8bG3iQvwbAXwddWWAZHdSTXXVhPKepXH/Z1cu+9fRl2GrjruYdZtLBFZy6qMskRT4jEY95xECqTZ8h2o8WTay/j/NhH8jbS1+/nUck9K1/+txDYPeW7D3/74EfVeE3m3t1nYnx76hEJKb6xKZTXvrTDn/gyZ+yYK8/IUFreP378eQQMEEF13RUNX4r50act38tURMb42EDhVu4NVAeZjxWFn/oh392439zdCevR38tZn8XWHQeWIEg+DtLZ2y/V4Dht2PKpEYJ+H+NEhsNuGEPCIESeHM5FRvkwTkxKHBe5C076Do9GG6PoYPQwYMc6G/fcyFHyD0P8AAqmExudkn0VFVrxHlzJmDR4xqMVVYcA1mCB4RNqIXa020/aIRegoT9NTBFyIRpKIRJ6INtqEsbuBFPGIWaB2RqlGOt5YIQEBOSwoE80YVCA4bRBIiaImZAYmiP94ai/xMiL3JIk/Iu5FMfkShLk0goHXGClhZ3mUdsvsd0WPgRgfgcFXCKFSA0p9gADSA0DPCKDKBNzVGKkBhOkvgjlKiIXMSI8OKI71aLlHOL/qOJHMGJDuSJnyh3LSiKf7gczyKIHrGKrcgxrPiKrgiLzXJUsvIcq3RCafGM3BhOGdgg4Jga3ShA5OhoHfGEuqc+yKhuoXhpd9eM2pg9TcGKrCiNsLiPsbh46biN5iiO3liPj3hfFMVzBPmLBgljF3VUc7GOD9COmmSAUDeFBrdusjOKzjRUPCGN+NgAr/iRrNhITVJC92VISFeSL6SLy4OSJFkkKwmNW+iSJjROqQKREv9JQRgpd27UY34YPSY5YJXTc/YSlA5SK0XTRXP1XEX0koVilC7SlDUJazfJEez4fT20k3qYRj6ZRqO4Jbeib96hiJI2Lu2BlGMpk4xmGCYjLfxDlrP2HW05lG+plmX5NnVDEjiJlVd1jDxJhavFMBqgAV9HiRuEluRSIHmDMd4jlol5LIsJTogJkJCJGHNJk4cBl2AyYSWxl9rll1sJWxkJAYNZmNtmJ425URaic9GXmhx5V63zMl8Sl85lH6xpfa65lKJFeFJjh08YkXzpY1x5bIEJAU9YmOcnm9+yLZoRm60JKuDUnDOknJxCnXYZcs95lyT4c4fhm1c5keZGnDv/xjDH2YHD5zxFRWqVyXGoc0DqCSRnh55M9Z5cFJ8/mJ68tp4mlyMjsZc52UPqAzjUIxOIlmu1p1BmYp8G+nxUop8Ad5/zmZ/wuXaOtqDUd2Jit2Wx1J9WCZz/CaC3I6At6RNq04bjqJlm1hvUF3D8UaJpeaLXSSLdsaKH16L0NZscCjhut6MRADgiqliH4qI0ykIxmqIzqn0xxF9lKKRI2pAuwqSq56Tuwlw4yks6yqM96qNTB6Sac2SYSJuvqRZeKi7+yJJzlpLSQaTcOKbUUqZqiYgDk6ZuuqYaSqbZaI5suhl3Shh5ahq/RoJw6pS56ad0GqcyoqZ4qqFmKJ+Y/zUUXrqoENqoO6WoKHM9zBkWj1qpjJpXtORv7HGptJQRojqqpFqqpnqqqJqqqrqqrNqqrvqqsBqrstqqijmCSnpUtVp29cdPDuqNushV4tN/H8irE6qrw6oetmk9wdOIqEEZfgpugoisGqWs1dOLzSqdksmsgvGmDHmW2ioZ3Go513OX77FQ4eo25Nqg1woa1DqosritdKKnfkpO0nqQh/mtmHEjLYQkMxkgWsatvAih+7Yp8aGvAMuUZeYj4aiij+ZfUHSw5cF8DrsgBrtoSEJgK7awRyqx/vqwFtsT/FqGHUuxGhulbZOw9ao9JouWKOt1IQuMHTt2fxJLpZIi6P8hsy+rsRyCs8kVjOBisyo5rCPqs+KaMk/psjmrs0PCswhLsz+bLDeLtEl7kksrtT3rtEXrMlErtEaIKFqrkurKE+xiKVQLlmJ4tZv6Hr8RiCQ4tpVStsiChk2btsQ1IWz7gVUKL2ubiB/otnICt7nohnMbqby2t2GbE357KUIJRX4SlVkLS4Y7KjNLt1k0X0FRLjakMGDDLlPaLQNbnYJ6qHh5uZRiLluzucXSuT73LZj5p7DyjNcCulMZloZZkDJjujSDumT7XLDrHtjycW1auwp5u5l7QYLDubzrubPyu0T5rKP7NChptJshvOzUS8WrMICDMzlDMc3UTytzsqz/O7utgxJ7w0DsYzPaKzHcu0/ey5irG7vNS2vuC73hm65dR77Ea75bk704o76Ds1bfy7L1C6YzhL+S5E77GzgQ47+8YzEBLJazOXTjy23LC7z6whXl6zfn66O6y74yKqx4Y5l5mcEaTDNaqjvHyzMgSMAROpmLycJUNDdpM8L5W8ImfMIdDJR5aawhzJY0LEk2jL04nMLd+8Ee2MNLs8P5lzROWYc1fD6Z50DsE0S9ozyeY6IM2kLSU4khhcDoYnfqM8UZ0MCi9jtX/KJZbLBb7LONicWqo8XjcyTX+ytgnFU3TMViYcVDuYS1B8cXx8UEMMe/FMVhnMB4XMZsDJ1u/4ykfjy+iVyzTWqpgFyWxNjFvnRDnahpPZRPQDTGFaNBqyusLVTAHGrJlJTJ4qlJxtvAoGxxtrqbwKZComywpFy91zts31XHcNTJrFxC9junAcZxemm9l+wruKzJuLzKn+zLMAzMyXq/IDfLsOw7QHxGbLaC4KfK51JeAltE+BlRmWLL+ntawpmCwqnN+pSFfyS+jDRb4bzOv/xF7qxl4uzFEwB+5nzN6Owr3AzPzSzPQ9hF1YzJ15zP3gVbcSRhnNPO8Tyu88y4/rygfDRGTLJAdPxGrcWHU7hw5ZbOQZV6EmqhOuWoINVLF013yIxgmMfRubxMiJV97ynSu5pNs//UrdBKS+J80ioNZBqtTCytTB5NrNEk08da0iGl01fF01UIZD+9Q0FN0zH9byM9qTAd0lI90yUNVT6U1AcHiinN1Vn10s9MWhlH0nt1YCS1YAqW0UutY7ijVbg61pJa1lQt15xa1Tc9qWfNV1t9ecVWkWxNd2G9VUjVUzdC1wu11+Sc1uemjFOo0YMd19O6lIh9FsF81yCd14l91PdcO37V2KAomsloO2K9gKRl1yZLXVPC2agF2o4t2ppE2oStWZKK2pJcm8AK0la2mWlJr1nN17Tz2V09nEq9WrFdO6U9f7Vp07dNhtrI2p6dWn99kY+tebAl25Kt3M492QyK24n/VdW7rZy66RRnRs5crZVqbXDh5V0QBgHlNc+13bQ7Ml/l3dnn7daAvV3qDXx7WDsRdqY9GN9rON9qgn1jDagiO7H0Dd33DY9daU9R9WD+7d4KbeDcjeADal3RNW7m7df47dU6tt8Rzt4T/t4BjtmOO7L0feLLTdEKXuBnlmYsONz9TXcpN2RFRoqUemt6UWNMbGY4VoW9N92AudPHBmc5PmFV1mX2kWUP629MfmUtG+NCPuNEXuNGfuNxBuBhFuVjNuVB/plWPncHnXnF7UM4Lmc67qleDrJftmJQ3uNk9uMKG8iVBppqjYIYneedtmzn2bC44WuHNm7HzOflhtJk/65sDQNqf86xcjtmAXvBg6ZoXhbpQEFphd7YKd1dV+XnyTnpkFbpa1kyhI7Kmn5snN7ni85sD+roggvpoy7pgP7obm7p8ntmAwiKvSeFC2c7Dfdw3/Z4kOpquN7S1L2TEL7W+J0+v746pxl998Jvhxdug17sy6jrM87ry85wEuBuzh7sFBzt4mbt8ejYu56HZM7s3e5w355vnvpvz859hkrsG2GMJH7s247tDrSlryRzRkdySBd5KSeAxJ3u+d3rE66R0OTv0350jcTwRCp0AT8Z9t7f+K7tCE87/G5LEO+mEv/wFB+ATEfw+q7sGY8AG7/wHffvUzl0HQ+tAA/yAP84eZ0Wd5aHUro8mnnnso4HrWdX75L3djVfeU+H84RcfvT4eo3X85BLoWjH9PMKeSFP89de8Atn9Lg8iuxZeFDf9OwJ9FRf7iV/31+teVq/n3fR9V6P9syh9rLHm0CPz0VucBSZcubneYfd3dUH6gTqfXKP5XSPzX2N9C+I99pNuc1Nv4aPgYQ7pBCcnMyRk8g48MY+98xY+NMXyXjl6osv+ZMvfoJv9w1TxRZ+oHs/65Cf947v+PumPJyY68lY9ZRf9S/oxIfvqzHq+iKv51jO+5YP+7V/fyJorNv5f/xnq5qp+wRf9VJY98OJgM2ogLePjsXvxK9f+bAl+yOP/Zv/F/3Gb9qznPwhiNe4TxvKc4cKlv0WSYBGHprdj4jbrYRn+OrO6IRQmP6xv/5t1odemfQbGNAAEUDgQIIFBwIAIBDhwoQGAxCAGBFiAAMGGgqUKNHhRocIFTK8WDBjRIoWMRJ48ADBSgQFCggQ4JIlS5cwYbrEWWDmSps9Y+YsAAGCxoohR07kmPTjR4YbjxIo2RBiypk1f+5s+dImUJ07fW4FKpSoyYFPlSr1GABkSIJmi7Y9ejZp2rVO4xZFKFGoTKw0ueLEarVnzqpBh5LEK/XpYqQnCa6FzPZhxqh5I+7t2jfr38x+vxL2KxaxxbSMGcN9HBmkwZGVFZuOWxbq/0HVTUVSTqwXAl/NnHl79gl6pUvRExOfhN1aduraaeGOXaj7d2Df1D8DDn3YOOnXyTUup91ccuvjk71/dxy+OWvcBtQCkJhSaO/qwG8C7Vm4OMTEpc+jfk+82p6r6L34HpivL986E+ynnPLLLqP+uoMNQAHXk42ACZFLzsILVSPQPcumQhAC+jgrbDD8bNJPO/648887Dz+ELEQDI5LPRAXrG06r+x5kMUKJNjSvQ/BojCzE1Yqs8Egk68pwwgMT1IwnAVIEC0iYeiTOxYEmdI7JxQwKcyPxCpISxxKrZGlL+xzECcKc9vsSxoWeM41MyfQckCAwjTIytbPO9NPOKf91ZNPNHlXU8srNDEPvTzxPK6jMjjCsE6RD2bQSyx/jDHJOLwWSNMM8K90T1T4zhZJDSgVFC1NS3WMKPjWpREDRnRrkirouNdAAoqb+DNNSPu8UU7la6yqw1k3bdNS6LLEr7NdgCRjWTtuWitW2JpddjdiQjFUV2W8DrLFZdJ/tdEdGqfXLWmHvFBfWuZY8d0B1GWI312h39RHO6R4VCth5PaqXtkHxPRXcbEFUuFtzG0aXWVrVsyylHH1dcWAuDUvp4IYAKHBVVJmr0VSzKmZIXXBJ3Bhgru47EeQHRFaoZIj1RLnVZCljeSGdk7y05yVdjU01l1mGeU2ZO+6sWpv/cVZr6JR5xvjon79T+uKXUdIY14+B9JhgCELGFlmSRdz55Ky33ZqkoBGy2md75w6zya4dQmpEsIUSm1OsAAe8sUp1dhhJcNlbedml0/M7x8AFn4lw0cxEHO8PF7+t8YozfxJKu+Pu+fHJPjp0cspXsvwwzNlOnEbOJwXaca+dTB3R1Xdq3fDHQA/dttFf/Rx2zS+cXeXaiwcPa8tajyB66VvvPSO/G9tX7SWDh/vckpp3+3nLpZ+eesJHun6272vlnHtkkVZ2VvXadx9Q4tc/vegboSc/AvPPt56tInUx4W2vfrSLH/58FzHxEa5//vvffualrOzRxYDuQ+Dy8FdA/w5yL4PokZ9cWGY0k50HKqZD3tvaZkL8LQxuslPeaVAoIBKu8D8zJFTsrhY38tzuXi/cXAzHhENZwRB+Q/QhR3xmRB6251I5PJ7WWEhEkzFxikkUIcp0mDfvmC6L84viB0fixS+ia4v2gw0Zv9hBoh3xKGrMIht3eJ6K1NGOd8RjHvW4Rz720Y9/BGQgBTlIQhbSkIdEZCIVuUhGNtKRj4RkJCU5SUpW8o8Uq5/W3DgkA2Ayk+8TooQ6SbxPgnKTEamIJ0vJOMakkpSlHE8a3SOjMKpweE8pEC2hmMIP5tJIu6Rh58Y4y1+OTHs1vOUbiam3Igazl8s8FTCh6EZfMv+zis4MZTWj2cxpbk2blLKgBZGpSW9CE5zclBU1zalKY47OTKYsVBNBKEdyHYsj32Rn4kQINzStE2mnDFS57rnOV4aTnO+sJz4L2s6DPjFV32MhGNsosYHKU27sm9s+4VknMf3TovcDo0MUOiaJ7vCHD10aLdnjvI2GNISh1CD4uMVPgcZTjCAEEKxoqkWbwtSEEeUpR2960duwtJ5m7ClAF5genbYUo0L1KVFzykCnIhWqSlVfUcNXVX6m9KdfTaBVX4pVuxj1oWJ1jV1AOlNsPrU8rPRcU7u5rbcKM65Unev76gpQDvTVr38FrF9VapC9RvWdZ7QUXbmjVpKa1WT/bl0s3ygm13RatbAAPWwUE6vXyA41sJ8F7GD72VLv4bWyim0o1u52LGC65qirfc9JW0ukhanWobPVFoUiEtgJ9Na3v81ABjawAdD29X60jZVtWdtM154VtkdlIsLspFHllgu3qXUbbMe5xISU6im8/W14gzvc4nLguNOVy2Zly1xx7TS9Z0VSe6t6r/U2R76vVSJ8afSnkYA3vOFtXXAFnIELXIC8gk3afZ2b3/rWRsFljBhCL/RgCMc2vx+iMIShu9/c9hew//1vgAdMYAMTF8HKWVtb46hfDBMQlk+9MIgq+EkYSzhJM85kjW+bLhd7uK8gBjKIIzheExv3ojg+/yBad2wxW4ZOx8tlMmKD6N7tdtfFq1QylMPV44z8Nchf9u2QhVtk8x75yjTOsnV5rJi7GdTN2osRUbvG5ghbWHQp89by5sxUC7OVngz1aOzeIiYvB7lsWPmyUIL7174N2nDFYuibDRpovDk6q5Cm353j/OjIWLrNkQb1pDtqS0/X+c36RGr89kxov3750DtJNAQWjeCckYXTlJU0oEct6NzaOMkehUyptBw82jlM2GrGoPKMzR2JFPq3bLLKq3v031kbOcXu1GwQgb2WY1fZikALdq+X7EFlB63bTX5Ssc3N7N22OrzQ1oq0s0LtDDAaW+eWMi9HHe5QG3PYEONiWP+jgurNwjDgMR14RvuMbjyjEaezEiABnO1bqaHoaQNzyX+NnHCiFXzKDpcqxAkumXQv/K4cb/i/Ow7ypQ565SpPuRBFapFmu/vZ8eIRzjFeAI2XGeV3hjnQZU7YUaZtopBzsl1xWfTH5o/YSldmRJret6QPVUM0b/dvf3MdrFxHV4v6yW+NfHWptw3pJbe6K41uUqdXPapkF9kt803O5Kh96rN5etqxDpEf+3brwYmav1T09azcR+xlhvva5Z7tZLay6FT3Gfrcfkq1Q16KAUS7TyuP9zliXnFQ56StCt0jK33FU4DvepBm0tuxbx7VSMu75h/P+ch7nomUn/3rxRT/e9yDu/MS4T0Pi8J3d5Ne8D45vYpST3jWI971Cof95IU/e+BffmV9qn3Un5L9pAHc+sNcDPdR7P3uLV30HOjtTA5wANPjnOtPo85MWk/9spf/+uQH5WI2X337d3/l/Rel8Pu+8fu//Fs6AQRA3yvAgxOl80s/lli/9vuY95Oa+GOJ+UNAA7y/BWS5Fxm6BFwrl+IWBfK/Djw5EewzddlAE4wNCVMtX+q7mZDAwvsKRwGSwviYyoGAjVPBErS6kAuqCOtBAmRBgUNB5xhCBSxChDvCi0hCrtHAgLKn7IJB9JsAGUS+N5ETUMHBR9FBHryYFfzBpWrCq6qwJlEOy6uo/wozrFFTw42Ao7NAQ6B5w5mbjL5KPamZwV7xCrAoDAmQAJjYDjZswzSkPZTCoiyaw++oQ6IjRMxyw0NcQ0JcRLlpxH66Qw7IQ/fLwrEJPOXzC0AUxBNKRBGqRKS4xHg6OkWkQznjMOgrI0PktBaDxS+SxUt7ReKDtxr8l2jrDF7EQsIZgAGotVpkRUZ0RVpcRVNsxVmcMLbBNjlsRlxURrZjRmR0RgGpwl2sQSz5uxmECWEkxqqBRuxKilv0tpYpR31jw9CpGxXTsCd5x26Kx/gipr7yxUbRlRsEGAjRDEAcxtKYx8qqx1fMvHaUx3WExzJyR4WkR4ZMyEzMR1Dxx/9HIbwGYROAHACBdEiChEh7LJLg0zJfExpoEklkS5W94b/PazCSpBtiwowKtMhO1MJ/GZzCsR5tOskacsm1CUnpG8lx88mVvL1x60mdBEqUPEqY3A0GwQ59tEkarMiblKB7M8mk5Emh9CpYYkmM2Uqu1DavvJ24A8umAwlfEorosRLOmMHSQ70q6RL++8qyzKuSvA26VLGzHEvFw0u208u77EuzVMfJSMsIWMu/aMvjA0X62A+7hIvAFEzH3L2GS6Gmex3l4UDsMzslekK+zLXMnK+D6EFcWZDfIJu/6MIeAaBijD5NCybL7IjOBM3ZXDDWnEzXJBTYJBPZpMzX3Mz/yzwJ0ixNPRQYeDFNw7gccsTM3szN34xNWzuKsoSrFrQ0yePK6aQg6LTOFwO9AVKMmKRBPvRG1ORErkjOhNs+sMTO2qlO20OzocqUI5LO7jQz3SLLHKNP7IFO8JzInfsU4ZhJ83QdkfuZ+YRPAj2iRzw1yeqhDlRQUGMs6MigB02eCbU0qgAO/5yWgeFFAZXQoUPICpW5QUtQQlzQ9Uy4Eg3REWLQ9nBQE4XQFv1QEhlPafnPT6xBDx2NF11RbHOLyAKrrMrGzWzQTfsP8GHHjiqPIJ2qJC3SiAPPmhHPmgTQuNxRIx2sIV3FJ8Wq+NFStuPSj1qeL2287ZiYr2pS/xV7UukIvIoDChudlhaBDiwNKDKlOxfNsyw9xNhDJfQCqrZLNuQgkj+1PD71wMhxGo6ZUl5ZkX2ElNDL0zrdU7frU4bR07mbqEqN1HMpVEp9EUuVVEz9PZ3pFzet0oCZGdXLCgka1CM9O3ITVHEjq+yKsaM7NtFauJ40pVuVwlwVyl01lFvRHc1w1HfBSLPxTvFrrDrT1TLh1dLCr2l61snyVZgbLWW9q2hNpzQhEdXBwtNLVTcRlWQdwGUdwVo1qYQ5V1+DRB1qLiByoTNdVn3JLUyTGDqdJxk7s34hPLC7UY4pmGt5mInS1k1tQc15V1AqWHn1HHptm4XF12RcM/+CXTAoyRd9VQ9+jUp/LU6AhQCDWbuEtdf1aleEHUhygbRM3aZwQ1j9cdc23BvYTNnfI6m9MZqmCRy2vIod6RK0EZ6TTclxsaFzYlmZFVqVJVpu60iUPVqaXcG/NNpxOlCbzRqcHdZHOc2aEQqfVRugzayXhcSY7TeDu9OGHczP/DiaWiifRNvKLNuD/cuVupFuBZzd6Yvqucy29U21ndezHdu0hae1BZ5kK1M981tRxc1YMlvJ9JDcsVuqxMm8/Vu35dvFfcmS+rNvOy/MhTNYbSJMxKjEzTzv6cHMaiDAeaAIqsr0gSo5QtxyTaAZyzTPJd0zm11D3dzQvSDanaz/0tWf0y1M8lFdF5kg9rRdFsXPkm0hhptZKLqiXwUifXveoGta572hUlSzdGTAPKGihw3L6UVJ7pLe64Vehf1e8qVe7V3CsVix6MUm8E1H9R1DUnxEzkVaWapf3S2hLsJejdLbMYzD9/rft/PA/M3cKDQNS1LgBWbgBnbgB4bgCJbgCabgCrZgCman5H27/TNcLNO7DP61Daa/fPVgEQbhQBVhizqj+O3OkRo/3WXhZ1LhWpKy9by6GZamytI/gipBiu2mHcZhdLo7ZQpiGGZexR2mIL6mH146JfZeJiZiXRJiIm3iP/0z/0XESMTGIM2qIMREK+5cKqspOwTjXMPi/4oq4347YzjkYcvVvZNC42lERS4mQypzYbgN49B8MvlJ4zeOsTgerCsW4Cz+wbLaqg1z1r2kYzQd47GaYbmlLDhOqkfWqkj+40nGVT7zMxZjC68qLU22M64C1vxc5Gwd5UKWLLOSZDPM5PyxZBfE5F4FZVGDZVZJlU8O5bp0ws6KqvICrVZOKxk9WFzbTNQiF1zWW4+z5QgdZtOKzF0mLWrd5GdeZlL25c8C5sv63N/NS86K5hBMZpLz5mOW5lw+rXHWY19FZGySrpT5rg8LMiIrr/MyR2at1iPGNOSiL1ql3nxGr9ri5/DdoXYW4+fi5Ouy2KPwLxCT5+Ki54K25/91Ruh0Vi90vabmoq6All+FyTCIbLA5Wwsfs7kgE7EBK7ADGztw6+g1OmjxWOkV++hOq9d6/try1cuFBOhmVVrIEOm+izXCGTESQ2nEU+mZhuia7ueXxOnksmgHM+p0ri719cnXLcB4vTEuqzmfBjMgE7OhHiB83tuKXQ8kI9zQPBOyJjeIPuszw0+1Hmusbjet3uoQ+5+GTunW5U63plewbk6I5TG+xhC91lc6O9cFrepdqzTtjGsrBDJ5W4lYqzafI0fCXjjD7k1KW7Vbc2Y1TrUO3mk+s1fR1TVVk2nKDu3d7SDMLm2kmbj/cmwEgOx6o7XJBm2hvd3OVW1+q23/Yh45I0WmUivsGD1s0uY3bLvOcivuiGvtK4TLeGtTgKE3e7u2hjrubbtp4+ZO61ZHa2S891XCkuTu6t63nfab5eZGecs48ZJta8O37rZeKLxu6s7u8Y5v9xJvIgTvkUtqcQLRQlHukX5AT5xST6SOnjNT/Rbol+vv+FQ4j3PbCSU6znZw34Tw0UJwqfa3BYe4rGZsitM58nTTAg8vMJRwcSbbCvfvCwfscz05l4s5DGfxZi6J+gPTSXVSWfpvrfvFt8TCwYtKXzy8PqXxxQu+umM6Kn5dG+akIb/TJCflxLs7J9e7HPe7HV9MaPFxaUnv5hPy+wxcG1dTWWJyvpVy/xP2ckvp1BtP4NyDxe0syjU/vxjMCresyAa5crdEtAnAQPgu1yJ3vO9GYM8M8x0G9O31c0Ln8wQ8dPMjPjnnC2CsSZrpQ+bTc+dj8/s9cx3+80QP9EXXPrnBdEGH4gNMTxAEdfzb3kolvgBHgAikSajcuZ2TP0vPwFQ/dQ58plpnwZfF1hfRdTHiddj19VIPdE533WzCOjlfCVevc4r0Q/gDmFnv8ugU9jTP41wndlu39hMtp1+HqWA39Rsu0XCX8TLkY4mzwh5XVTsPFS70ixxkCaEAww8sdnNt5BHszEb80ym0l3yXRAImQx1DwjD0QYDv4ntPwXtMdyxf94DZQv+r6EIAlXef83cY23eEH3h61/ZyF/hd1vj1BUJzX14IO8XZSEWO0sU+JM5mB1C3PE5RFIBBfMSSf9VJZEOaB1RCpsRTMcQ9HvlY5PlW9PltVHlOZHl4cXmnhHmZ33lK6fk0+3lbDHpkHPr+VQqcP3n5WUa5QEe+Jnr6gHSw+0aaDEfAGcZi3Hpp3GKpHsibn0a270i3X3uvj/szfHu6z0Ru3EPnVveKLHuhOHvlTPurv3tMbXu7n3vDr3uSL3z3BtrBx2JaJL7+dPhedPfTy0gJCEipeHzuZmmQPMgKa0j3rs17fUbSN+CInHznhkrihNPM33yM6PxobF+D7EqEBP3/2xd91R/zpfZjXiPMppTJ1u9HmoRc9EHK0A/KYUt+3V/+8G3+onz+375K5VdKrWTK4+QL4k++jY13nAS+6A9Ll1zKn7T+rGT+6nf+609/wIRMvxxMiCjMwwxXVaXzZ2dMF2HcyXj/VYxb2QAIAAIHEixo8CBChAEWMixowADDhQQIJKxo8aLAiAsdQow4ESPIkBk1cgwwEQKECBEQIBAgoADMmDBd0hTA8mbLmjRh4uyJACbKiR8FPtQ4VCTShBoDlPRIMSlUg0ubMjwa9epUgkUlCrVKcGNIsAqXkgWw1SQBlDhlso25NqbLtjxvzmUJFCWEiRvPdvU6UCxGwFLJ/07l23esSMEFCRfuiLYr4rBMlTKOaNZx36eDE08eW3kv5rQQ3sp1SxfuS7lv3+LNSwB01cMHFVek/fczbK6QZ3cO3Hsw7suxd2+WXBs304cAdMu+yttp5q4MlXNFOXdmapk+sZcmXSAu26CvF1J/3Nz5YqPRpZM3sNw8cfRf1a/X2/79evnAh9ef7p55fPq9B11/91UHwXXfZWfaW+C15Z2DMYnnH37RCTgfgetRCKBQF96WYXQbwtehhwPyp6GBJwqFHGMj7QeiXuVN9MADDaa2nYIR1nWTTjuF51qM/6loH4tZKUaYhuVxSGSRlr334pCvKTkik02CdSRZSQq55P94Vjb0ZHpLaVkhjTbuaFeOC56ZU49tiRekiSh6eeVvJsIo5ZZUdjmni2HS11cAU8rJJ5gY/imdciPVt+ieTIIkJqCJAtCVdQX45N2DPWFXk3anvYnnbYwWyJWTF0GKqHuKihpibKVadOqKknIpqlOuHgdioKlWuCqgrX5p6qGgCkQpgpZeimZ3mqYZIWtACrsrryv6ahuUmeUaarTskfrrq8Feq2q2TDrqG66SgrtqrXUmBV1RwwpFo1qXlrbjpmqm2Wxf5kJLq6/ysavrufxu6+9w+s7K6sDo/ZtetukSrFu7k777QLw4Josmp2zVhG9XBus5qH0PP+Zxw/0qXDD/wPsy6vDJEKc80sHafhlctxQS1BW8ox3Lo02nZSzTxj9J6KzNfvJq5GfAFm3o0STZWVbN9+3XtJM03yq10eg6bTVlS0s8I8U675yTjTreK/Rd2uoL88e9Vp101N9mLfDMcF8tN9Nav12Z0ljvxzZhg9Fd21k3T1wx2fKmmal3KGmggVV4+wk41PMNrtTaH07GdcAIq/tX5mxTnpXlK3MrVegmju506YvauljhA+EcNk4uHVsv46fd9Xjkqe/dIsOmU7uc73XzHbzrp8P+suarvx7znoRDdLfxn7PNb0JnKQZ2zhZrfKPid9EYeXLTd7218nknn735nqE//J3ssW/9/9N0wh+l/AhF7P7vV2Ovv2O2RwAadU9ZbQHP7YY2Ps08aX/PeR/94iet+VHPfhHE3wQBeEGk3Q961IrY8B5VJ1hZ63TaM9nsWjO2FSKgNRMqCwjpJ8Jqjeo3MSQYDQdVkj45B0sStNUNT5ZDz1GFZSnECwvH5kLXBC6IPRxhsGS2w0JhBYo/NKH5QuibIZZQMLHj4W1ERrdcTQt97lqiStIYgSUuMTPuUptj5lOcJ3owIl+kIhijIsEq3RFLYhRee7jlx5a1jY+hCRyYTuJCNaqEjS5049ekRUbADJKOhdzTJHtTySrW0T+ChOIfk+dJ0kWNM9BDVZH+JplTxiqA6f97oCkviUpSXi2WDTuhFkW3Slm2snKl3OUtXXk8Q9kyWpl8nfuKeTRcyrB5wDQmM0WYS80Fc06k1OIeOyZMQuXxgdFippfkGLVvbjOcYRwnr8BpJXH6L50PeSc84ynPedKznva8Jz7zqc998rOf/vwnQAMq0IEStKAGPShCE6rQhTK0oQ59KD4B6SESruchEr0QRaNjUVE2M5an3GgNJxrFzIBUhxgdab4g0jQwWlCa+CvKSn/Zt1nBVGt9cylNVWpTmcbtYzX9Xy3J9VKd/o+Sm3slF7XJS2wi1U85XWozkfnAp8Y0qDP1KVFNd1OhUrVXJQyX51zFmJ/qTZOfY5H/oTRC1st103msq18gS2ZU/gHPeWu9aFvhek3C3JVDrOSoWPmaVbbiUXPD1OtdOcpOp9YVsYPFa2HdGliyJDak54QSIu3qSrBy1m2fHCUGZZaut6X1rWrdbFlHW7fSTjaQ2axSGenE2s+6NrSSVA/SZmtU0P61s2E1K2+hCqncGta0dkTtGGN7VN0Ct7asRBIml1vc1h5TuLg143RpK7eM9oUD3v0ueMP7XaotRVZZAiRpuQpc83JXtKtVL4bYi9Lbpveq8dUVdAH7Xvt+SL7QEy+Aw0ve02Y3ubKFb3/xe179Hpi/MPOvbRE5zb1ud8E1rG9P78ub9Yh3Ah7+MIgz/5CBDWwgwN4FrMdoxkFfblVyaH2aW2OZkRTDbcW0/KWLkUO5GO9yxszjUodBLGQRk9jEHEBxyl5s47e2mMbHW7JUk0m8JOsYxnrtqDNzrGII3jioknujUIIsZCEvUcRmzsAFLlDk8bLqMupVcmMxkjrmPjnOF5lzdrecWZDgWbLAO6ycmZcZMY/5w2U+M5rVXGI2l9DNV4XzngP95ioD+s7Mwyyl7WyRPl+5zpG29JcG/d1Ck7rQjkQJkRd9YkneEYd5bqqPYY2U3Wp6ebLmDJ2j2mqLeKDXvp6jiXztgSiDLo6RnAh4S61sQ5861eCF462N82ps7vqJuTZVtat47f9XZRshwu41sCMibGL7WGXJLvWajqVsVGfg2eNx87ZaWljbGLWL1pNR9FQ377Oa1d7sq1D/9h2ZzkUZ378rQQl6rYCFM7zXCH84xBPua4YrwOElKLiQRO1dZaf7UuuGgIjdDRqAV6+b9O63Z/8d76M2+LLpad1tVY6WgG9ysX5FqsGrh3CFU7ziHoh4xIVNcYtjXHZhHrWQx8YdYym9AGMOOZsdzdhpurTRBsncpy1pdY5MNdpV79VBsK6RnXug5z3vtQXSrnaem33hFg/Z1XXVlXODuOkIXCFMnt7uqIu9y5wcEW36zmRCbl0rP2Yx4cEe966Tve0N94Da1152x/v/HOFw5/rckV533c3Le2vKu5BXfa2T73jWLNcTZYUUGb8f53q/HT2/S4/rOL2+PGNpvAI60AGhM1z3wtb90H3t+5+XwL3XyvzGk875iy2f6acZs+htzxvZS/tOqY8smFhPGdfbW0SrHzywuO9Z7/MG98Nne+53L/wOBL/Xw7c8fe+TeRDvqE3OZ4n9bacs8IB41QQAKfVcnum9FgCeT8Ksy3wJRQHSlQB6lCwt4EGQHfCl3++pX/ANn+5lYAeIgAjAX30ox/x9WP3pxJrkX8+YidN9mP9BIA1RHWOtCgu+4LtBRXtpE4kw4AwiIAEawA1GoMRN4Pl5wPBdoPppoO5x/6AHVpR7IBvSoQn+9cgJCg0Ugk/t0IRPeNgK8mD+TM15OCCjlFQOzk0PeuGigOHJcYgeJaAZ1okEGqEGVmAQul8Gop0FJKFGLSEBnJsTsolOlA0J3h8fXuEEZKHicWGA7FLMrKH7QJIOhpYielMXImIhPSJBtKEbBuEbflsmpp0dkhQeJh9OHMAB9AiE/KH34AhOEGJ+iGHhAZv4pVR9GGKbbR8r2uAqqs8sDhw1KWEsDgTCpV2vjYAwDiMxCqOwFeMw0iEnXhxWSQwo3oQokiLn2d8pKksqHtlEgOEhXlHr1aICaqGFeGMG6eIr2mI44mIrvpw4/h84MiIA/KIFBP8jMhbjMc6jMtYhM36gTj3jEwYNxkAhsijIaqCN86FE9IVG4b1W/FEXyxlGQtqW8WlXQyJkIdLegBnX3jhkr8Bj5JEACXybEBphBXpk5C0jB9UUP/Kh/v2jNAJNFCbIjhgkNmYSiqAjemGk8WjkFlpkauGk/ejkOPKkgUnkg1Eke3Ck2nkkSLrhSJJASeLjSe4jB/jEShKkNAZkCfrIW0iABLhEkFhThAHezDXXaYFlHX1VGI5VORUJv6AlrZUlbiBl2lHcEJ5dSJpd5CGcZqGFd1HlS6KGPxJkVt4dmnClV+KJWV7SzQmgWiZmW3pVWgqWY5qOW5LlcSGHXFoAXVr/oF1OIMXlZQnsJRPaHUD6DBWqpBXyTGsMwADABl2xCFqOS0g4UK7ll7RIkUjQ5rQxRmzm22y2j58gpdn1mkeanVLeZc8t46ZJJWlepRSe5hRW4Wq2Zvnwm5f0JrnFnXVaCXZ6HVEAZ21amH3g5m9up3DaZXH23HF6JsMpZ0WgJAcsnUsGpkviSGD6BFeypqLo5qOtU1LwZ0+ZE1IAaAX554CCpw96JFN6gEemJ8U1aINeYgfo5XtKpXwCZmoGZFWyZBTipwToJ34QqAFyU24iaH82CVSI6GsaaIk2E8IpqEgyaIMaJ4SSgIRS6PwoEr2YxnxmqGneZ0+0hhuRVRpW/9rq5OgYSqLfZd13mkeR1hqTCschCsSL1qjuVSmMamCNRmgHQCjCfZBOVYp3aGgf7l+ZHouQHgaR0qDdTN29ZdWTMmmUrmkjyiniDQSdFgSWcumeuuGWwqiXMiOSooRKPGFpOGc/muLOpM0NnpBflMiIFhFaQCpO2RBqUSqC4emlHsQJnADQQVynImOnfurDdSr1SaloFGpOHOqZ8gw1LmoBfIqmqgemOliTOkWtZpjh0WquRuqu4iqneiqplkCoFuOoDqupWtmsHgimqMY02suONssLCQcaTp+0rWhjqAg5dkuBZmu1uiK3jmgTGSUDCUSn/qmVGiG6QminBodhIP/OvDCIVUKr8+1omubGiGxrN2IrSQClvtIiv1qGv1rrDIkrDJGrQZzrumZpBi6sR7Zr0uCbmD5n7vwj87mkmzBRitziSWWTiHCsgNQgkeCbO4ZsAnYJyZ6Hwi6snzpsp4qSxBaLxbKFfdJrKWbsyGbcOXZsWMIeyOqHyKKszpYs0J7sx+7syq5ryy7sy44KvpWJaX7e4tBsT0whzraSUC5kKu0bd8Eel5ilyYkn1lofWIZt1woKq3SqhGJgjK5tB0Ds1z5tjUQtIOIO1Vah/cnEp3gt6pUt144U3w6KOfkQ4KJt9/kn4Vqf4faK2q6tHGai28It6kkKsXQcVt7tj/r/iL0SjXl1lmpVqrV0Lmd9rnqFroJ5bhmBbqScbnQswAI0roQ+7hyGpIRKrl9RrlBMbAIxH4cyi6dwLuuCFelelelii/CmbumurvGGy/D2VPF2zkS4Luxeouyybe2eAEWREZgVkOdhrt32KMd8I/KUVQOyqcuML92UbyOKL8ylbxg+Kfsub/S+7gk4rI2qq8uegOuqT8Qc0e46K4cekI8yavxCbw2p7wCODJXJ1ViGEskYk8loXTYucF9Ib/067NKua6fu7y6yY0H47wpV5fdiaEDurd908E362UwJ3kWqcNywcE+68N3AsAXbbwaj6wYvwIvoCwiPjQhPLfgSpAl//1nWCu7pRalhwXByybABKnEKd1pUHRck1jAG4y/T6q8OO9Ud9XDi1KzZeI/jQA4DEbEucY7K+BvmXJq+mXEnRVDxWNCntbH0nI/rWnCn3jEe57Ee7zEWc7BCbPHhiE0Xm+kXG1CsQgDvjPEbHzHiyXEanw8TGzB5zsYiR/IZp9wju08d0y8fd7In93EW/7ErGQT30I4hYywgljAELJAciaiENZXHvukGQVA7rY8GFaguLaJW3TIdb7Iv/zIwB3MdIzC1Kk8pI87lLt3/ogQrh5ErQw2xxTIFGWwuQ6Ith52JZlc1y2JN8rImCzM4h/Mwv++vXtf2hg0yJxFOtFF0uf8m9s1eaSnWruYVPBeXPM8qPV+rPVsWPr+zPlPOPd+qOUdSzqSzOrMEO4+rdFmbDJpUP7vgttYgEGURlu3rPjt0k+ZzwcYzPws0bB2YIrUGI63RqX3KUHRRH4FS4iHZJ4Hr+qJXSrt0Ao9RTKujBLP0yqVXSOPFSJe0ST8FShtb2IbShdX0YsEvTAu1wK10USt1zZmvYl7mixHTMy3TNrmUMqFLNAlVVtPKVm/V11n1ncJSVWv1Wt5Ydtqk63w1T/VNNWkfVYe1WY+1Ksm1V181V5f1XSfmXKETDJ711mp0ESshX5uVW7tTYR+1NYuKOqGoy+nyX0OUZE82ZVe2ZV8GNma/U0AAACH5BAFkACkALBEADQBaACYAhf///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtJ6qsGOrPzu+/zK5/zK4/yy1/yip+Syl9SWo/9Ccjs91K4yhtE+kuDt9TzGh7yKb9R53v71qYqtRMOZFOa0vRY9NV5dEBok7DFIzP0xohTo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj/AFMIHEhwYICDAQoqXMiwocOCJSJKnCjxoUUAAA5a3MjxIcWPETsyxKhRpEmRID+eHIixZcuVMBtK1ECzJk0HDiaadOkypk+IEW3axKmTI8+jAH4qFRi0Js6nT0NeRNpz6c+mN6FGLfGQKlWrMbFq0KpV6kKvSMHCFEsWqlmCB9F+VYuyhNCxbYlyhRsAQEqQGOnWvZtXb0ECiP9+DCyYo1gQkCNLhvw2BYEUJURo9sC5c2fNIhoPrjm5NAiziAlEBO25NeiIJUXLLBGidgjTk1Enzry59WfNsBPKnm37Nu7IETMiVF3Ct3POwWMPJxixeG0FCi5cSMA9gQULyREG/2D+3Hl04dOp07aOXXt37+BLiD8YsbzviIilp8dc4v137aCJ8N559DVnn2f4EaBfehH5ZwGAoA24VwoIYXagZwItuB9TJXz3nYQSGqSRgRd6kCF6G6rnoQUgdmdWhSReeGKKCkW0YovcVTYQa8+BRqNHJWj34XsJ6EgQj875+ONsQrJIpJHqKbYkkAEGCCVQUk45W5WvTahQUoqppKV6WeFEU22UeckSZl0y4Kabq2k2Jpl4makBmqepKRCYbb7JQJyhzcnhUA5wl5WRAMA5kZ9/LsqAoGwVmsCheqaQaKMSMUqRm5DyxiVk2BmJUAOklmpqA26SytiYgFYJqgJXBlhw6qypNiCoetbZdqVABGBgKga+lurnrQNVl2sIV6am4HLLxsXTmMAG20BKjD5KUH7MOjvXlNI2gAG1jC4kHrbbzlkqsKRW+2ZD2IpH0nzEdpsuA7PamkJAACH5BAFkACkALFQADQBXACYAhf///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtJ6qsGOrPzu+/zK5/zK4/yy1/yip+Syl9SWo/9Ccjs91K4yhtE+kuDt9TzGh7yKb9R53v71qYqtRMOZFOa0vRY9NV5dEBok7DFIzP0xohTo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj/AAMIHEhwYIqDCBMqXMiwocOFJSJKnCjxIYCLGDNeDPCwo8ePCimKjGhRo0mOIFOqDDmSYsmMAk1uXEnTo0QNOHPidOBg4sKTAWQCQFmzKMSIOnXy9NlQqFCjUFkq5Ul1aQmGTmVG3ZoCac6qVUn+zHqSq1GvO8GGvZqQbFmzNdFqULtWYVC3JuGulJuWbk+2Ke7izahXJd+5fv8iJMB4MMbCKeWCmEy58mSxKRgTcHwRMkjJlkNj1kw6plOinh9GDME6RGjRgElrNi0UdeqGq1u/tjxatu/ZBG93zN06hAIFFy4kWJ7AgoXev30XFK66RHHWx5Mzb/4ccIDopb+T/6buMOJ258lFqBexHbN48AQEyiaPu8R5C+nXtwd8sKD09/HRV14Jzjm33352EfRfaQLWV6AFBzKHWX8FVVhhgwxF9GCEy02IkIUWYlhdcgZul4CHCYE40GMi1kcihCai+KGKQbVY3Xo4iiBjW2TZOGCO6+2YAmc+JuRVVTixdhl/CJFFW5EIHUlVkq6BIKOTgkF5kFw8LZfWlY5p2VUJU3mJGJiDiRkRkOpNdpyMNN4Vk5olsCmCmwoIqeJMYkZp3XWsCUmheASx2OeYgAbK5EHAyRffinnZiMGkDVTaEgOYZrqYgo/2KGmllWJwaaaYJkioYJFCCSqlDZDqKkOPFg861IVaYgAqqJjeCupBAQEAIfkEAWQAKQAslAANAFcAJgCF////6/X5nPf/3/D/zOb/VuP3tMjmaNb/Pcry/8Kh8LVBocDdq7C0nqqwY6s/O77/Mrn/Mrj/LLX/KKn5LKX1Jaj/0JyOz3UrjKG0T6S4O31PMaHvIpv1Hne/vWpiq1Ew5kU5rS9Fj01Xl0QGiTsMUjM/TGiFOj9eKytFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACP8AAwgcSHBgioMIEypcyLChw4UlIkqcKPEhgIsYM14M8LCjx48KKYqMaFGjSY4gU6oMOZJiyYwCTW5cSdOjRA04c+J04GDiwpMBZAJAWbMoxIg6dfL02VCoUKNQWSrlSXVpCYZOZUbdmgJpzqpVSf7MepKrUa87wYa9mpBsWbM10WpQu1ZhULcm4a6Um5ZuT7Yp7uLNqFcl37l+/yIkwHgwxsIp5YKYTLnyZLEpGBNwfBEySMmWQ2PWTDqmU6KeH0YMwTpEaNGASWs2LRR16oarW7+2PFq279kEb3fM3TqEAgUXLiRYnsCChd6/fRcUrrpEcdbHkzNv/hxwgOilv5P/pu4w4nbnyUWoF7Eds3jwBATKJo+7xHkL6de3B3ywoPT38dFXXgnOObfffnYR9F9pAtZXoAUHModZfwVVWGGDDEX0YITLTYiQhRZiWF1yBm6XgIcJgTjQYyLWRyKEJqL4oYpBtVjdejiKIGNbZNk4YI7r7ZgCZz4m5FVVOLF2GX8IkUVbkQgdSVWSroEgo5OCQXmQXDwtl9aVjmnZVQlTeYkYmIOJGRGQ6k12nIw03hWTmiWwKYKbCgip4kxiRmnddawJSaF4BLHY55iABsrkQcDJF9+KedmIwaQNVNoSA5hmupiCj/YoaaWVYnBpppgmSKhgkUIJKqUNkOoqQ48WDzrUhVpiACqomN4K6kEBAQAh+QQBZAApACzRAA0AHQBmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGhwN2rsLSeqrBjqz87vv8yuf8yuP8stf8oqfkspfUlqP/QnI7PdSuMobRPpLg7fU8xoe8im/Ued7+9amKrUTDmRTmtL0WPTVeXRAaJOwxSMz9MaIU6P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wBTCAxAsKDBggITKlwoEIDDhxAdBmBIMWHEiwAmVqR4kSDGjBstRvSIUWNIkR8vnmyYUuXKliVPwux4MsBMjBtt3oy4kYDPnQ97/gQKQKjPoyQ/mmR4tGnSmBWbSp160OhUqgZzXpVKUKrWrUgDeA15EKvTmgbNIkV7sG3VlW7drkwYt2DQuSnqesSLMiVfonNhJg3ccvBLoIR3ztWrcy/euhL5DuxKwODdk2EpW3ZJsXJBn09xktWsUzTmthLbSl7NurXr17Bjy55Nu7bt27hz697Nu7fv38CDCx+eu4TxErOPI5etPLZxB9AdGH/9PPp01tWjW1/ON7t26dxXGv/XoOF7dPLXT44vb94B+vAU15OfT79+eoby6+t/v9F4iBAgBCjggAH+d99C/gFI4IIGwidQgv8tyOB/IRwIoYISCkhhhcspV8J/CihwwQUJlGhiiSOG2KCHCYY44oknpqjAispZYAGKF4igowgn7ijCiwnY6KGNOPrY445ACsldjTcmYNyJTwZpQXMKMVlilFeWUKKSFh5HpJNamhgllw4mZNyXMEp5YEVnNpmmknMZ5+OcO64ZXwl00mlnlSVoVyCFAWq3Zwre/RkhCIKW+WCY5LXnngZZ9scoe+aRFymbeO4YYIghBujjoHJqCgKnCnhap6JmfkihchsOymerx8EuehIGtGKgHK0NNKAcA7wysBGuuh6XK6+79npSrrkC2+uyvq4ELLIN8AptrgwFBAAh+QQBZAApACzRAE0AWgAmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGhwN2rsLSeqrBjqz87vv8yuf8yuP8stf8oqfkspfUlqP/QnI7PdSuMobRPpLg7fU8xoe8im/Ued7+9amKrUTDmRTmtL0WPTVeXRAaJOwxSMz9MaIU6P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wBTCBxIcGCAgwEKKlzIsKHDgiUiSpwo8aFFAAAOWtzI8SHFjxE7MsSoUaRJkSA/nhyIsWXLlTAbStRAsyZNBw4mmnTpMqZPiBFt2sSpkyPPowB+KhUYtCbOp09DXkTac+nPpjehRi3xkCpVqzGxatCqVepCr0jBwhRLFqpZggfRflWLsoTQsW2JcoUbQG5auh3FZs37NgWBwwT8VgW8USyIx5AjPy6MOLFijIw5OpbM2WzlzwTiei2ZWWaJEKhDcO681zBoxKKpki69MGJq1asjR8yI8LXv0AiD0659+nYIBQouXEjAPIEFC7uD/34dXPhwoMaPJ1/e/HnE6genH/8O/3n29RQRmzu3oFyEexHqv4MXDxy0+evpu7O/8B5+c7PgSVdeAJXddx5TJTz3XHwlMGhQgOQVSCBsCR2oUEQKWsCggwJB6GGAFl6YoIIb/tcaXx9aF6Jpyi2oXgKFEURSipityOIFLnJ4Fm8f1mgjcf31F2NBl/n4I1BBvjekQEXydORATUFFE2qTnciSYrEl9SR6duGF05S4DXlZlltyOZQDzGUlZpMvbckWmgmoaSWTbBr5Y0RJuvcYckOmiNCMdtqIZ557KrBkCn7OWCZBtmUXwqECjdcbcGQuiqCjj845kITkBXfUkxiE2sCoKTFg6qkFSdppX16BOuqoGJQheqqpCwmY5WJbvipqA7P22pCqf/KIkKUYvPqqqca+KlBAACH5BAFkACkALBEBTQAdAGYAhf///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtJ6qsGOrPzu+/zK5/zK4/yy1/yip+Syl9SWo/9Ccjs91K4yhtE+kuDt9TzGh7yKb9R53v71qYqtRMOZFOa0vRY9NV5dEBok7DFIzP0xohTo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj/AFMIDECwoMGCAhMqXCgQgMOHEB0GYEgxYcSLACZWpHiRIMaMGy1G9IhRY0iRHy+ebJhS5cqWJU/C7HgywEyMG23ejLiRgM+dD3v+BApAqM+jJD+aZHi0adKYFZtKnXrQ6FSqBnNelUpQqtatSAN4DXkQq9OaBs0iRXuwbdWVbt2uTBi3YNC5Kep6xIsyJV+ic2EmDdxy8EughHfO1atzL966EvkO7ErA4N2TYSlbdkmxckGfT3GS1axTNOa2EttKXs26tevXsGPLnk27tu3buHPr3s27t+/fwIMLH567hPESs48jl608tnEH0B0Yf/08+nTW1aNbX843u3bp3Fca/9eg4Xt08tdPji9v3gH68BTXk59Pv356hvLr63+/0XiIECAEKOCAAf5330L+AUjgggbCJ1CC/y3I4H8hHAihghIKSGGFyylXwn8KKHDBBQmUaGKJI4bYoIcJhjjiiSemqMCKyllgAYoXiKCjCCfuKMKLCdjooY04+tjjjkAKyV2NNyZg3IlPBmlBcwoxWWKUV5ZQopIWHkekk1qaGCWXDiZk3JcwSnlgRWc2maaScxnn45w7rhlfCXTSaWeVJWhXIIUBardnCt79GSEIgpb5YJjkteeeBln2xyh75pEXKZt47hhgiCEG6OOgcmoKAqcKeFqnomZ+SKFyGw7KZ6vHwS56Ega0YqAcrQ00oBwDvDKwEa66Hpcrr7v2elKuuQLb67K+rgQssg3wCm2uDAUEACH5BAFkACkALBEBjQAdAGYAhf///+v1+Zz3/9/w/8zm/1bj97TI5mjW/z3K8v/CofC1QaHA3auwtJ6qsGOrPzu+/zK5/zK4/yy1/yip+Syl9SWo/9Ccjs91K4yhtE+kuDt9TzGh7yKb9R53v71qYqtRMOZFOa0vRY9NV5dEBok7DFIzP0xohTo/XisrRQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj/AFMIHEhwYICDAQoqXLgQAICDDCMydAhRosUUDjNmvBhRo0aOCj2KBABy4EiPJU+e5KhypMWDLVcyhBlTZEQCOAnU/Mgwp86dDhf6HEqA5smKA4n6NDqy4kOESqMWRUj16UGpSqlq3YoV59WhW6F2/bo0ocCwYsuWLYiWbE63SM+2nUs1Il2tLK22DXqRIl2+FoECniiYZ8OdTDsiDmA4ZOGNhB+TnHmX8dPBC+/65ehVbFXIN996Rmiz59SvTEvbHS3TYufPW0vKnk27tu3buHPr3s27t+/fwIMLH068uPHjyJMrXz67hPMSu59D1y09t3MH2B04v309+3ba3bN7/59eMrx47eQvOteg4Xx29t8trm/v3gH89Avns9/Pv398hfr1J+B9ETkXQgggJKjgggke+F9BBiLI4IQO4idQhAdOSOGBITyIoYQaKshhh9NJV8KBCihwwQUJtOhiiyumWKGJEaa44osvxqjAjNJZYAGMF4ggpAgvDinCjQn4aKKPQBpZ5JBIKklejz8m4NyLVyZpQXUEUdlill+W0KKUHj7HpJViupglmRYO5NyZOGr5IENvVhmnlBw5Z+SeQ86ZXwl88ulnlyWI1yCHCYo3aArmHZohCIq2eWGa7NVnnwZhFkgpfe6xlymdgA6ZYIopJmjkonqKCgKpCpjap6RunjjIoXQjLkporc/hahEGvGIgHa8NNCAdA8QyEBGwwj4XLLHDFmtRsMEiW+y0xl6ELLQNEIttsAoFBAAh+QQBZAAqACwRAc0AHQBmAIX////r9fmc9//f8P/M5v9W4/e0yOZo1v89yvL/wqHwtUGhwN2rsLSeqrBjqz87vv8yuf8yuP8stf8oqfnQnI6MobRPpLgxoe87fU8spfUlqP8im/Ued7/PdSu9amLmRTmrUTCtL0WNXDOPTVeXRAZSMz9MaIU+VGo6P14rK0UAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAI/wBVCBxIcGCAgwEKKly4EACAgwwjMnQIUaJFFQ4zZrwYUaNGjgo9igQAcuBIjyVPnuSocqTFgy1XMoQZU2REAjgJ1PzIMKfOnQ4X+hxKgObJigOJ+jQ6suJDhEqjFkVI9elBqUqpat2KFefVoVuhdv26NKHAsGLLli2IlmxOt0jPtp1LNSJdrSyttg16kSJdvhaBAp4omGfDnUw7Ig5gOGThjYQfk5x5l/HTwQvv+uXoVWxVyDffekZos+fUr0xL2x0t02Lnz1tLyp5Nu7bt27hz697Nu7fv38CDCx9OvLjx48iTK18+u4TzErufQ9ctPbdzB9gdOL99Pft22t2ze/+fXjK8eO3kLzrHgOF8dvbfLa5v794B/PQL57Pfz79/fIX69SfgfRE5F0IIHySo4IIJHvhfQQYiyOCEDuInUIQHTkjhgSE8iKGEGirIYYfTSVfCgQoo0EEHCbToYosrplihiRGmuOKLL8aowIzSUUABjB2MIOQILw45gkAt+miij0AaWeSQSCagJHk9/piAcy9iKSUF1RFUZYtagllCklw+B+FzTF45potaTvmglyWkieOWb+YXp5VzTsmRc0b2OWSdAJbgp5+ADmRegxwmKF6hh34woqLjFbgme/XZh4GYkrZIaX3sYcoQn0MmmGKKCRrJqKChfjCqAqX+aeGZI0owF+urgc76YaECiaCrCNLtyutzvkZ0wrAn9LqrdMSeYFGyw/qqa7IcMXuCsyJAW1BAADs=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}